<!DOCTYPE html>
<html lang="zh_cn">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
<title>CIS 1.10 Self-Assessment Guide | RKE2  Latest</title>
    <link rel="canonical" href="https://documentation.suse.com/cloudnative/rke2/latest/zh/security/cis_self_assessment110.html">
    <link rel="prev" href="cis_self_assessment111.html">
    <link rel="next" href="cis_self_assessment19.html">
    <meta name="generator" content="Antora 3.1.10">
    <link rel="stylesheet" href="../../../../_/css/site.css">
<meta http-equiv="last-modified" content="2026-01-15"/>
<link rel="stylesheet" href="../../../../_/css/search.css">
<link rel="icon" href="../../../../_/img/favicon.ico" type="image/x-icon">
<link rel="stylesheet" href="../../../../_/css/font-styles.css">
<link rel="stylesheet" href="../../../../_/fonts/css/all.css">
<link rel="stylesheet" href="../../../../_/css/site-extra.css">
<link rel="stylesheet" href="../../../../_/css/vendor/tabs.css">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=SUSE:wght@100..800&display=swap&family=SUSE+Mono:ital,wght@0,100..800;1,100..800" rel="stylesheet">
<link href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css" rel="stylesheet">
<link rel="stylesheet" href="../../../../_/css/vendor/light.css">
<script src="/docserv/res/lightheaded/analytics.js" type="text/javascript"></script>
<script type="module">
  import { defineCustomElements, setAssetPath } from 'https://d12w0ryu9hjsx8.cloudfront.net/shared-header/1.10/shared-header.esm.js';
  defineCustomElements();
  setAssetPath("https://d12w0ryu9hjsx8.cloudfront.net/shared-header/1.10/assets");
</script>
<!-- Default English link -->
<link href="https://documentation.suse.com/cloudnative/rke2/latest/en/security/cis_self_assessment110.html" hreflang="x-default" rel="alternate"/>
<!-- Link for the currently processed page -->
<link href="https://documentation.suse.com/cloudnative/rke2/latest/zh/security/cis_self_assessment110.html" hrefLang="zh-CN" rel="alternate" />
<!-- Link for the English page -->
<link href="https://documentation.suse.com/cloudnative/rke2/latest/en/security/cis_self_assessment110.html" hreflang="en-US" rel="alternate" />

<!-- JSON-LD for doc metadata -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "name": "CIS 1.10 Self-Assessment Guide | SUSE Rancher Prime: RKE2 latest",
  "headline": "CIS 1.10 Self-Assessment Guide",
  "description": "CIS 1.10 Self-Assessment Guide",
  "inLanguage": "zh_cn",
  "dateModified": "2026-01-15T00:00:00Z",
  "author": {
    "@type": "Organization",
    "name": "SUSE Product & Solution Documentation Team",
    "url": "https://documentation.suse.com"
  },
  "mentions": [
    {
      "@type": "SoftwareApplication",
      "name": "SUSE Rancher Prime: RKE2",
      "softwareVersion": "latest",
      "applicationCategory": "Cloud Infrastructure",
      "operatingSystem": "Linux"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "SUSE",
    "url": "https://documentation.suse.com",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
    }
  }
}
</script>
<!-- end JSON-LD for doc metadata -->
    <script>var uiRootPath = '../../../../_'</script>
  </head>
  <body class="article">
<script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; mermaid.initialize({"startOnLoad":true});</script><shared-header
language="en"
languages='{
    "en": { "label": "English", "url": "https://documentation.suse.com/en-us/" },
    "de": { "label": "Deutsch", "url": "https://documentation.suse.com/de-de/" },
    "fr": { "label": "Français", "url": "https://documentation.suse.com/fr-fr/" },
    "es": { "label": "Español", "url": "https://documentation.suse.com/es-es/" },
    "zh_CN": { "label": "中文", "url": "https://documentation.suse.com/zh-cn/" },
    "pt_BR": { "label": "Português Brasileiro", "url": "https://documentation.suse.com/pt-br/" }
}'
enable-search='false'>
</shared-header>

<!-- Leaving as a comment, I expect it will be required again next year.
<a target=_blank"" class="survey-link" href="https://suselinux.fra1.qualtrics.com/jfe/form/SV_bEiGZbUNzLD8Tcy"> Documentation survey </a>
--><div class="body">
<div class="nav-container" data-component="rke2" data-version="latest">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <button class="nav-menu-toggle" aria-label="Toggle expand/collapse all" style="display: none"></button>
    <h3 class="title">RKE2</h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../introduction.html">介绍</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Installation</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/quickstart.html">快速开始</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/requirements.html">要求</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/configuration.html">配置选项</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/ha.html">高可用</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/methods.html">安装方法</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/private_registry.html">Private Registry Configuration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/registry_mirror.html">Embedded Registry Mirror</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/containerd_registry_configuration.html">Containerd 镜像仓库配置</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/airgap.html">离线安装</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/windows_airgap.html">Windows 离线安装</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/server_roles.html">管理 Server 角色</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/packaged_components.html">Managing Packaged Components</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../install/uninstall.html">卸载</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Upgrades</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../upgrade/upgrade.html">升级 SUSE® Rancher Prime: RKE2 集群</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../upgrade/manual_upgrade.html">手动升级</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../upgrade/automated_upgrade.html">自动升级</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../upgrade/roll_back.html">Rolling Back RKE2</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Security</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="about_hardened_images.html">强化镜像</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="hardening_guide.html">CIS Hardening Guide</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="cis_self_assessment111.html">CIS 1.11 Self-Assessment Guide</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="cis_self_assessment110.html">CIS 1.10 Self-Assessment Guide</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="cis_self_assessment19.html">CIS 1.9 Self-Assessment Guide</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="fips3_support.html">FIPS 140-3 Enablement</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="pod_security_policies.html">默认 Pod 安全策略</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="pod_security_standards.html">默认 Pod 安全标准</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="secrets_encryption.html">Secrets Encryption</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="selinux.html">SELinux</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="certificates.html">Certificate Management</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="token.html">Token Management</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Datastore</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../datastore/embedded.html">Embedded datastore</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../datastore/external.html">External Datastore</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../datastore/backup_restore.html">Backup and Restore</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../architecture.html">下一代 Kubernetes 发行版剖析</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../cluster_access.html">集群访问</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Networking</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../networking/basic_network_options.html">Network Options</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../networking/multus_sriov.html">Multus and SR-IOV</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../networking/networking_services.html">Networking Services</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../networking/windows_bgp.html">Windows and BGP</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../advanced.html">高级选项和配置</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Add-ons</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../add-ons/helm.html">Helm</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../add-ons/import_images.html">Import Images</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../add-ons/gpu_operators.html">GPU Operators</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">References</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/ai_conformance.html">CNCF AI Conformance</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/cli_tools.html">CLI 工具</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/linux_agent_config.html">Agent 配置参考</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/logging.html">日志</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/metrics.html">Metrics</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/resource_profiling.html">Resource Profiling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/server_config.html">Server 配置参考</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../reference/windows_agent_config.html">Windows Agent 配置参考</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../known_issues.html">已知问题和限制</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Release Notes</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../release-notes/v1.35.X.html">v1.35.X</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../release-notes/v1.34.X.html">v1.34.X</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../release-notes/v1.33.X.html">v1.33.X</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../release-notes/v1.32.X.html">v1.32.X</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle" aria-label="Toggle expand/collapse"></button>
    <span class="nav-text">Older&#8230;&#8203;</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.31.X.html">v1.31.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.30.X.html">v1.30.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.29.X.html">v1.29.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.28.X.html">v1.28.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.27.X.html">v1.27.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.26.X.html">v1.26.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.25.X.html">v1.25.X</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../release-notes-old/v1.24.X.html">v1.24.X</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">RKE2</span>
    <span class="version">Latest</span>
  </div>
  <ul class="components">
        <li class="component">
          <div class="title"><a href="../../../../admission-controller/1.31/en/introduction.html">Admission Controller</a></div>
          <ul class="versions">
            <li class="version">
              <a href="../../../../admission-controller/1.32/en/introduction.html">1.32-dev</a>
            </li>
            <li class="version is-latest">
              <a href="../../../../admission-controller/1.31/en/introduction.html">1.31-latest</a>
            </li>
            <li class="version">
              <a href="../../../../admission-controller/1.30/en/introduction.html">1.30</a>
            </li>
            <li class="version">
              <a href="../../../../admission-controller/1.29/en/introduction.html">1.29</a>
            </li>
            <li class="version">
              <a href="../../../../admission-controller/1.28/en/introduction.html">1.28</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../cluster-api/v0.25/en/index.html">Cluster API</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../cluster-api/v0.25/en/index.html">0.25</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.24/en/index.html">0.24</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.23/en/index.html">0.23</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.22/en/index.html">0.22</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.21/en/index.html">0.21</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.20/en/index.html">0.20</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.19/en/index.html">0.19</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.18/en/index.html">0.18</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.17/en/index.html">0.17</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.16/en/index.html">0.16</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.15/en/index.html">0.15</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.14/en/index.html">0.14</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.13/en/index.html">0.13</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.12/en/index.html">0.12</a>
            </li>
            <li class="version">
              <a href="../../../../cluster-api/v0.11/en/index.html">0.11</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../continuous-delivery/v0.14/en/index.html">Continuous Delivery</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../continuous-delivery/v0.14/en/index.html">0.14</a>
            </li>
            <li class="version">
              <a href="../../../../continuous-delivery/v0.13/en/index.html">0.13</a>
            </li>
            <li class="version">
              <a href="../../../../continuous-delivery/v0.12/en/index.html">0.12</a>
            </li>
            <li class="version">
              <a href="../../../../continuous-delivery/v0.11/en/index.html">0.11</a>
            </li>
            <li class="version">
              <a href="../../../../continuous-delivery/v0.10/en/index.html">0.10</a>
            </li>
            <li class="version">
              <a href="../../../../continuous-delivery/v0.9/en/index.html">0.9</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../k3s/latest/en/introduction.html">K3s</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../k3s/latest/en/introduction.html">Latest</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../os-manager/1.8/en/index.html">OS Manager</a></div>
          <ul class="versions">
            <li class="version">
              <a href="../../../../os-manager/1.9/en/index.html">1.9-dev</a>
            </li>
            <li class="version is-latest">
              <a href="../../../../os-manager/1.8/en/index.html">1.8</a>
            </li>
            <li class="version">
              <a href="../../../../os-manager/1.7/en/index.html">1.7</a>
            </li>
            <li class="version">
              <a href="../../../../os-manager/1.6/en/index.html">1.6</a>
            </li>
            <li class="version">
              <a href="../../../../os-manager/1.5/en/index.html">1.5</a>
            </li>
          </ul>
        </li>
        <li class="component is-current">
          <div class="title"><a href="../../en/introduction.html">RKE2</a></div>
          <ul class="versions">
            <li class="version is-current is-latest">
              <a href="../../en/introduction.html">Latest</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../suse-observability/latest/en/classic.html">SUSE Observability</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../suse-observability/latest/en/classic.html">Latest</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../rancher-srfa/latest/en/about-rancher/what-is-rancher.html">SUSE® Rancher for AWS</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../rancher-srfa/latest/en/about-rancher/what-is-rancher.html">Latest</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../rancher-manager/v2.13/en/about-rancher/what-is-rancher.html">SUSE® Rancher Manager</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../rancher-manager/v2.13/en/about-rancher/what-is-rancher.html">v2.13</a>
            </li>
            <li class="version">
              <a href="../../../../rancher-manager/v2.12/en/about-rancher/what-is-rancher.html">v2.12</a>
            </li>
            <li class="version">
              <a href="../../../../rancher-manager/v2.11/en/about-rancher/what-is-rancher.html">v2.11</a>
            </li>
            <li class="version">
              <a href="../../../../rancher-manager/v2.10/en/about-rancher/what-is-rancher.html">v2.10</a>
            </li>
            <li class="version">
              <a href="../../../../rancher-manager/v2.9/en/about-rancher/what-is-rancher.html">v2.9</a>
            </li>
            <li class="version">
              <a href="../../../../rancher-manager/v2.8/en/about-rancher/what-is-rancher.html">v2.8</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../security/5.4/en/overview.html">SUSE® Security</a></div>
          <ul class="versions">
            <li class="version is-latest">
              <a href="../../../../security/5.4/en/overview.html">5.4</a>
            </li>
            <li class="version">
              <a href="../../../../security/5.3/en/overview.html">5.3</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../storage/1.10/en/longhorn-documentation.html">SUSE® Storage</a></div>
          <ul class="versions">
            <li class="version">
              <a href="../../../../storage/1.11/en/longhorn-documentation.html">1.11 (Dev)</a>
            </li>
            <li class="version is-latest">
              <a href="../../../../storage/1.10/en/longhorn-documentation.html">1.10 (Latest)</a>
            </li>
            <li class="version">
              <a href="../../../../storage/1.9/en/longhorn-documentation.html">1.9</a>
            </li>
            <li class="version">
              <a href="../../../../storage/1.8/en/longhorn-documentation.html">1.8</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../suse-virtual-clusters/v1.0.1/en/introduction.html">SUSE® Virtual Clusters</a></div>
          <ul class="versions">
            <li class="version">
              <a href="../../../../suse-virtual-clusters/1.0.2/en/introduction.html">1.0.2-dev</a>
            </li>
            <li class="version is-latest">
              <a href="../../../../suse-virtual-clusters/v1.0.1/en/introduction.html">v1.0.1-latest</a>
            </li>
            <li class="version">
              <a href="../../../../suse-virtual-clusters/v1.0.0/en/introduction.html">v1.0.0</a>
            </li>
          </ul>
        </li>
        <li class="component">
          <div class="title"><a href="../../../../virtualization/v1.6/en/introduction/overview.html">SUSE® Virtualization</a></div>
          <ul class="versions">
            <li class="version">
              <a href="../../../../virtualization/v1.7/en/introduction/overview.html">v1.7 (Dev)</a>
            </li>
            <li class="version is-latest">
              <a href="../../../../virtualization/v1.6/en/introduction/overview.html">v1.6 (Latest)</a>
            </li>
            <li class="version">
              <a href="../../../../virtualization/v1.5/en/introduction/overview.html">v1.5</a>
            </li>
          </ul>
        </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
<ul>
    <li>
      <a class="home-link-dsc" href="https://documentation.suse.com/" title="documentation.suse.com" aria-label="SUSE Documentation Home"></a>
    </li>
    <li>
      <a href="https://documentation.suse.com/cloudnative/rke2" title="RKE2" aria-label="SUSE Documentation - RKE2">
        RKE2
      </a>
    </li>
      <li>
          Security
      </li>
  </ul>
</nav>  <div class="edit-this-page"><a href="https://github.com/rancher/rke2-product-docs/edit/main/versions/latest/modules/zh/pages/security/cis_self_assessment110.adoc"><strong>Edit</strong></a></div>
        <div class="navbar-item search hide-for-print">
        <div id="search-field" class="field">
          <label class="visual-search-label-bc" for="search-input">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</label>
          <input label="Search" aria-label="Search" id="search-input" type="text" placeholder="Search the docs" >
          <label class="filter checkbox" style="display: none">
            <input type="checkbox" data-facet-filter="component:rke2" checked> Only this project
          </label>
        </div>
      </div>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="On this page" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">CIS 1.10 Self-Assessment Guide</h1>
<div class="sect1">
<h2 id="_overview"><a class="anchor" href="#_overview"></a>Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This document is a companion to the RKE2 security hardening guide. The hardening guide provides prescriptive guidance for hardening a production installation of RKE2, and this benchmark guide is meant to help you evaluate the level of security of the hardened cluster against each control in the CIS Kubernetes benchmark. It is to be used by RKE2 operators, security teams, auditors, and decision makers.</p>
</div>
<div class="paragraph">
<p>This guide is specific to the <strong>v1.28-1.31</strong> release line of RKE2 and the <strong>v1.10</strong> release of the CIS Kubernetes Benchmark.</p>
</div>
<div class="paragraph">
<p>For more information about each control, including detailed rationales and descriptions checks, you can refer to the corresponding section of the CIS Kubernetes Benchmark v1.8. You can download the benchmark, after creating a free account, in <a href="https://www.cisecurity.org/benchmark/kubernetes/">Center for Internet Security (CIS)</a>.</p>
</div>
<div class="sect2">
<h3 id="_testing_controls_methodology"><a class="anchor" href="#_testing_controls_methodology"></a>Testing controls methodology</h3>
<div class="paragraph">
<p>Each control in the CIS Kubernetes Benchmark was evaluated against a RKE2 cluster that was configured according to the accompanying hardening guide.</p>
</div>
<div class="paragraph">
<p>These are the possible results for each control:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>PASS</strong> - The control is automated (scored: true). The RKE2 cluster under test passed the audit outlined in the benchmark.</p>
</li>
<li>
<p><strong>Not Applicable</strong> - The control is not applicable (type: skip) to RKE2 because of how it is designed to operate. The rationale section will explain why this is so.</p>
</li>
<li>
<p><strong>WARN</strong> - The control is manual (scored: false) in the CIS benchmark and depends on the manual operator intervention. The remediation section will provide guidance on how to achieve a PASS result.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_1_control_plane_security_configuration"><a class="anchor" href="#_1_control_plane_security_configuration"></a>1 Control Plane Security Configuration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_1_control_plane_node_configuration_files"><a class="anchor" href="#_1_1_control_plane_node_configuration_files"></a>1.1 Control Plane Node Configuration Files</h3>
<div class="sect3">
<h4 id="_1_1_1_ensure_that_the_api_server_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_1_ensure_that_the_api_server_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.1 Ensure that the API server pod specification file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c permissions=%a /var/lib/rancher/rke2/agent/pod-manifests/kube-apiserver.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the
control plane node.
For example, <code>chmod 600 /var/lib/rancher/rke2/agent/pod-manifests/kube-apiserver.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_2_ensure_that_the_api_server_pod_specification_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_2_ensure_that_the_api_server_pod_specification_file_ownership_is_set_to_rootroot_automated"></a>1.1.2 Ensure that the API server pod specification file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/kube-apiserver.yaml; then stat -c %U:%G /var/lib/rancher/rke2/agent/pod-manifests/kube-apiserver.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chown root:root /var/lib/rancher/rke2/agent/pod-manifests/kube-apiserver.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_3_ensure_that_the_controller_manager_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_3_ensure_that_the_controller_manager_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.3 Ensure that the controller manager pod specification file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml; then stat -c permissions=%a /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chmod 600 /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_4_ensure_that_the_controller_manager_pod_specification_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_4_ensure_that_the_controller_manager_pod_specification_file_ownership_is_set_to_rootroot_automated"></a>1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml; then stat -c %U:%G /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chown root:root /var/lib/rancher/rke2/agent/pod-manifests/kube-controller-manager.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_5_ensure_that_the_scheduler_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_5_ensure_that_the_scheduler_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.5 Ensure that the scheduler pod specification file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml; then stat -c permissions=%a /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chmod 600 /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_6_ensure_that_the_scheduler_pod_specification_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_6_ensure_that_the_scheduler_pod_specification_file_ownership_is_set_to_rootroot_automated"></a>1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml; then stat -c %U:%G /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chown root:root /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_7_ensure_that_the_etcd_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_manual"><a class="anchor" href="#_1_1_7_ensure_that_the_etcd_pod_specification_file_permissions_are_set_to_600_or_more_restrictive_manual"></a>1.1.7 Ensure that the etcd pod specification file permissions are set to 600 or more restrictive (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml; then stat -c permissions=%a /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>If running master only with no etcd role, this check is Not applicable.
If controlplane and etcd roles are present on the same nodes but this check is warn then
Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_8_ensure_that_the_etcd_pod_specification_file_ownership_is_set_to_rootroot_manual"><a class="anchor" href="#_1_1_8_ensure_that_the_etcd_pod_specification_file_ownership_is_set_to_rootroot_manual"></a>1.1.8 Ensure that the etcd pod specification file ownership is set to root:root (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml; then stat -c %U:%G /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>If running master only with no etcd role, this check is Not applicable.
If controlplane and etcd roles are present on the same nodes but this check is warn then
Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chown root:root /var/lib/rancher/rke2/agent/pod-manifests/etcd.yaml</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_9_ensure_that_the_container_network_interface_file_permissions_are_set_to_600_or_more_restrictive_manual"><a class="anchor" href="#_1_1_9_ensure_that_the_container_network_interface_file_permissions_are_set_to_600_or_more_restrictive_manual"></a>1.1.9 Ensure that the Container Network Interface file permissions are set to 600 or more restrictive (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Note that for many CNIs, a lock file is created with permissions 750. This is expected and can be ignored.
Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chmod 600 /var/lib/cni/networks/&lt;filename&gt; and chmod 600 /etc/cni/net.d/&lt;filename&gt;</code></p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_10_ensure_that_the_container_network_interface_file_ownership_is_set_to_rootroot_manual"><a class="anchor" href="#_1_1_10_ensure_that_the_container_network_interface_file_ownership_is_set_to_rootroot_manual"></a>1.1.10 Ensure that the Container Network Interface file ownership is set to root:root (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ps -fC ${kubeletbin:-kubelet} | grep -- --cni-conf-dir || echo "/etc/cni/net.d" | sed 's%.*cni-conf-dir[= ]\([^ ]*\).*%\1%' | xargs -I{} find {} -mindepth 1 | xargs --no-run-if-empty stat -c %U:%G
find /var/lib/cni/networks -type f 2&gt; /dev/null | xargs --no-run-if-empty stat -c %U:%G</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root
root:root
root:root
root:root
root:root
root:root
root:root
root:root
root:root
root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chown root:root &lt;path/to/cni/files&gt;</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_11_ensure_that_the_etcd_data_directory_permissions_are_set_to_700_or_more_restrictive_manual"><a class="anchor" href="#_1_1_11_ensure_that_the_etcd_data_directory_permissions_are_set_to_700_or_more_restrictive_manual"></a>1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c permissions=%a /var/lib/rancher/rke2/server/db/etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 700, expected 700 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=700</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>If running master only with no etcd role, this check is Not applicable.
If controlplane and etcd roles are present on the same nodes but this check is warn then
On the etcd server node, get the etcd data directory, passed as an argument --data-dir,
from the command 'ps -ef | grep etcd'.
Run the below command (based on the etcd data directory found above). For example,
<code>chmod 700 /var/lib/rancher/rke2/server/db/etcd</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_12_ensure_that_the_etcd_data_directory_ownership_is_set_to_etcdetcd_manual"><a class="anchor" href="#_1_1_12_ensure_that_the_etcd_data_directory_ownership_is_set_to_etcdetcd_manual"></a>1.1.12 Ensure that the etcd data directory ownership is set to etcd:etcd (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c %U:%G /var/lib/rancher/rke2/server/db/etcd</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'etcd:etcd' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">etcd:etcd</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>If running master only with no etcd role, this check is Not applicable.
If controlplane and etcd roles are present on the same nodes but this check is warn then
On the etcd server node, get the etcd data directory, passed as an argument --data-dir,
from the command 'ps -ef | grep etcd'.
Run the below command (based on the etcd data directory found above).
For example, <code>chown etcd:etcd /var/lib/rancher/rke2/server/db/etcd</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_13_ensure_that_the_admin_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_13_ensure_that_the_admin_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.13 Ensure that the admin.conf file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c permissions=%a /var/lib/rancher/rke2/server/cred/admin.kubeconfig</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chmod 600 /var/lib/rancher/rke2/server/cred/admin.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_14_ensure_that_the_admin_conf_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_14_ensure_that_the_admin_conf_file_ownership_is_set_to_rootroot_automated"></a>1.1.14 Ensure that the admin.conf file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c %U:%G /var/lib/rancher/rke2/server/cred/admin.kubeconfig</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example, <code>chown root:root /var/lib/rancher/rke2/server/cred/admin.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_15_ensure_that_the_scheduler_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_15_ensure_that_the_scheduler_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.15 Ensure that the scheduler.conf file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/server/cred/scheduler.kubeconfig; then stat -c permissions=%a /var/lib/rancher/rke2/server/cred/scheduler.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/server/cred/scheduler.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_16_ensure_that_the_scheduler_conf_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_16_ensure_that_the_scheduler_conf_file_ownership_is_set_to_rootroot_automated"></a>1.1.16 Ensure that the scheduler.conf file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c %U:%G /var/lib/rancher/rke2/server/cred/scheduler.kubeconfig</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chown root:root /var/lib/rancher/rke2/server/cred/scheduler.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_17_ensure_that_the_controller_manager_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_1_1_17_ensure_that_the_controller_manager_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>1.1.17 Ensure that the controller-manager.conf file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/server/cred/controller.kubeconfig; then stat -c permissions=%a /var/lib/rancher/rke2/server/cred/controller.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/server/cred/controller.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_18_ensure_that_the_controller_manager_conf_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_18_ensure_that_the_controller_manager_conf_file_ownership_is_set_to_rootroot_automated"></a>1.1.18 Ensure that the controller-manager.conf file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c %U:%G /var/lib/rancher/rke2/server/cred/controller.kubeconfig</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chown root:root /var/lib/rancher/rke2/server/cred/controller.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_19_ensure_that_the_kubernetes_pki_directory_and_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_1_1_19_ensure_that_the_kubernetes_pki_directory_and_file_ownership_is_set_to_rootroot_automated"></a>1.1.19 Ensure that the Kubernetes PKI directory and file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c %U:%G /var/lib/rancher/rke2/server/tls</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chown -R root:root /var/lib/rancher/rke2/server/tls</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_1_20_ensure_that_the_kubernetes_pki_certificate_file_permissions_are_set_to_600_or_more_restrictive_manual"><a class="anchor" href="#_1_1_20_ensure_that_the_kubernetes_pki_certificate_file_permissions_are_set_to_600_or_more_restrictive_manual"></a>1.1.20 Ensure that the Kubernetes PKI certificate file permissions are set to 600 or more restrictive (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chmod -R 600 /var/lib/rancher/rke2/server/tls/*.crt</code></p>
</div>
</div>
<div class="sect3">
<h4 id="_1_1_21_ensure_that_the_kubernetes_pki_key_file_permissions_are_set_to_600_automated"><a class="anchor" href="#_1_1_21_ensure_that_the_kubernetes_pki_key_file_permissions_are_set_to_600_automated"></a>1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600 (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">stat -c permissions=%a /var/lib/rancher/rke2/server/tls/*.key</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600
permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the control plane node.
For example,
<code>chmod -R 600 /var/lib/rancher/rke2/server/tls/*.key</code></p>
</div>
</div>
</details>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_api_server"><a class="anchor" href="#_1_2_api_server"></a>1.2 API Server</h3>
<div class="sect3">
<h4 id="_1_2_1_ensure_that_the_anonymous_auth_argument_is_set_to_false_automated"><a class="anchor" href="#_1_2_1_ensure_that_the_anonymous_auth_argument_is_set_to_false_automated"></a>1.2.1 Ensure that the --anonymous-auth argument is set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--anonymous-auth' is equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --anonymous-auth argument to false.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove anything similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "anonymous-auth=true"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_2_ensure_that_the_token_auth_file_parameter_is_not_set_automated"><a class="anchor" href="#_1_2_2_ensure_that_the_token_auth_file_parameter_is_not_set_automated"></a>1.2.2 Ensure that the --token-auth-file parameter is not set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--token-auth-file' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Follow the documentation and configure alternate mechanisms for authentication.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove anything similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "token-auth-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_3_ensure_that_the_denyserviceexternalips_is_set_manual"><a class="anchor" href="#_1_2_3_ensure_that_the_denyserviceexternalips_is_set_manual"></a>1.2.3 Ensure that the --DenyServiceExternalIPs is set (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
By default, RKE2 does not set DenyServiceExternalIPs.
To enable this flag, edit the RKE2 config file /etc/rancher/rke2/config.yaml like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "enable-admission-plugins=DenyServiceExternalIPs"</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_4_ensure_that_the_kubelet_client_certificate_and_kubelet_client_key_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_1_2_4_ensure_that_the_kubelet_client_certificate_and_kubelet_client_key_arguments_are_set_as_appropriate_automated"></a>1.2.4 Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--kubelet-client-certificate' is present AND '--kubelet-client-key' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the kubelet client certificate and key.
They are generated and located at /var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt and /var/lib/rancher/rke2/server/tls/client-kube-apiserver.key
If for some reason you need to provide your own certificate and key, you can set the
below parameters in the RKE2 config file /etc/rancher/rke2/config.yaml.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "kubelet-client-certificate=&lt;path/to/client-cert-file&gt;"
  - "kubelet-client-key=&lt;path/to/client-key-file&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_5_ensure_that_the_kubelet_certificate_authority_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_5_ensure_that_the_kubelet_certificate_authority_argument_is_set_as_appropriate_automated"></a>1.2.5 Ensure that the --kubelet-certificate-authority argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--kubelet-certificate-authority' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the kubelet CA cert file, at /var/lib/rancher/rke2/server/tls/server-ca.crt.
If for some reason you need to provide your own ca certificate, look at using the rke2 certificate command line tool.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "kubelet-certificate-authority=&lt;path/to/ca-cert-file&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_6_ensure_that_the_authorization_mode_argument_is_not_set_to_alwaysallow_automated"><a class="anchor" href="#_1_2_6_ensure_that_the_authorization_mode_argument_is_not_set_to_alwaysallow_automated"></a>1.2.6 Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--authorization-mode' does not have 'AlwaysAllow'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --authorization-mode to AlwaysAllow.
If this check fails, edit RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "authorization-mode=AlwaysAllow"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_7_ensure_that_the_authorization_mode_argument_includes_node_automated"><a class="anchor" href="#_1_2_7_ensure_that_the_authorization_mode_argument_includes_node_automated"></a>1.2.7 Ensure that the --authorization-mode argument includes Node (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--authorization-mode' has 'Node'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --authorization-mode to Node and RBAC.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml,
ensure that you are not overriding authorization-mode.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_8_ensure_that_the_authorization_mode_argument_includes_rbac_automated"><a class="anchor" href="#_1_2_8_ensure_that_the_authorization_mode_argument_includes_rbac_automated"></a>1.2.8 Ensure that the --authorization-mode argument includes RBAC (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--authorization-mode' has 'RBAC'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --authorization-mode to Node and RBAC.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml,
ensure that you are not overriding authorization-mode.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_9_ensure_that_the_admission_control_plugin_eventratelimit_is_set_manual"><a class="anchor" href="#_1_2_9_ensure_that_the_admission_control_plugin_eventratelimit_is_set_manual"></a>1.2.9 Ensure that the admission control plugin EventRateLimit is set (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Follow the Kubernetes documentation and set the desired limits in a configuration file.
Then, edit the RKE2 config file /etc/rancher/rke2/config.yaml and set the below parameters.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "enable-admission-plugins=...,EventRateLimit,..."
  - "admission-control-config-file=&lt;path/to/configuration/file&gt;"</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_10_ensure_that_the_admission_control_plugin_alwaysadmit_is_not_set_automated"><a class="anchor" href="#_1_2_10_ensure_that_the_admission_control_plugin_alwaysadmit_is_not_set_automated"></a>1.2.10 Ensure that the admission control plugin AlwaysAdmit is not set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--enable-admission-plugins' does not have 'AlwaysAdmit' OR '--enable-admission-plugins' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --enable-admission-plugins to AlwaysAdmit.
If this check fails, edit RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "enable-admission-plugins=AlwaysAdmit"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_11_ensure_that_the_admission_control_plugin_alwayspullimages_is_set_manual"><a class="anchor" href="#_1_2_11_ensure_that_the_admission_control_plugin_alwayspullimages_is_set_manual"></a>1.2.11 Ensure that the admission control plugin AlwaysPullImages is set (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Permissive, per CIS guidelines,
"This setting could impact offline or isolated clusters, which have images pre-loaded and
do not have access to a registry to pull in-use images. This setting is not appropriate for
clusters which use this configuration."
Edit the RKE2 config file /etc/rancher/rke2/config.yaml
on the control plane node and set the --enable-admission-plugins parameter to include
AlwaysPullImages.
--enable-admission-plugins=&#8230;&#8203;,AlwaysPullImages,&#8230;&#8203;</p>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_12_ensure_that_the_admission_control_plugin_serviceaccount_is_set_automated"><a class="anchor" href="#_1_2_12_ensure_that_the_admission_control_plugin_serviceaccount_is_set_automated"></a>1.2.12 Ensure that the admission control plugin ServiceAccount is set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--disable-admission-plugins' is present OR '--disable-admission-plugins' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --disable-admission-plugins to anything.
Follow the documentation and create ServiceAccount objects as per your environment.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "disable-admission-plugins=ServiceAccount"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_13_ensure_that_the_admission_control_plugin_namespacelifecycle_is_set_automated"><a class="anchor" href="#_1_2_13_ensure_that_the_admission_control_plugin_namespacelifecycle_is_set_automated"></a>1.2.13 Ensure that the admission control plugin NamespaceLifecycle is set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--disable-admission-plugins' is present OR '--disable-admission-plugins' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --disable-admission-plugins to anything.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "disable-admission-plugins=...,NamespaceLifecycle,..."</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_14_ensure_that_the_admission_control_plugin_noderestriction_is_set_automated"><a class="anchor" href="#_1_2_14_ensure_that_the_admission_control_plugin_noderestriction_is_set_automated"></a>1.2.14 Ensure that the admission control plugin NodeRestriction is set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--enable-admission-plugins' has 'NodeRestriction'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --enable-admission-plugins to NodeRestriction.
Check the RKE2 config file /etc/rancher/rke2/config.yaml, and ensure that you are not overriding the admission plugins.
If you are, include NodeRestriction in the list.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "enable-admission-plugins=...,NodeRestriction,..."</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_15_ensure_that_the_profiling_argument_is_set_to_false_automated"><a class="anchor" href="#_1_2_15_ensure_that_the_profiling_argument_is_set_to_false_automated"></a>1.2.15 Ensure that the --profiling argument is set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--profiling' is equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --profiling argument to false.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "profiling=true"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_16_ensure_that_the_audit_log_path_argument_is_set_automated"><a class="anchor" href="#_1_2_16_ensure_that_the_audit_log_path_argument_is_set_automated"></a>1.2.16 Ensure that the --audit-log-path argument is set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--audit-log-path' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --audit-log-path argument to /var/lib/rancher/rke2/server/logs/audit.log
If you want to change this, edit the RKE2 config file /etc/rancher/rke2/config.yaml
on the control plane node and set the --audit-log-path parameter to a suitable path and
file where you would like audit logs to be written, for example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "audit-log-path=/var/log/rke2/audit.log"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_17_ensure_that_the_audit_log_maxage_argument_is_set_to_30_or_as_appropriate_automated"><a class="anchor" href="#_1_2_17_ensure_that_the_audit_log_maxage_argument_is_set_to_30_or_as_appropriate_automated"></a>1.2.17 Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--audit-log-maxage' is greater or equal to 30</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --audit-log-maxage argument to 30 days.
If you want to change this, edit the RKE2 config file /etc/rancher/rke2/config.yaml
on the control plane node and set the --audit-log-maxage parameter to an appropriate number of days, for example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "audit-log-maxage=40"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_18_ensure_that_the_audit_log_maxbackup_argument_is_set_to_10_or_as_appropriate_automated"><a class="anchor" href="#_1_2_18_ensure_that_the_audit_log_maxbackup_argument_is_set_to_10_or_as_appropriate_automated"></a>1.2.18 Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--audit-log-maxbackup' is greater or equal to 10</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --audit-log-maxbackup argument to 10.
If you want to change this, edit the RKE2 config file /etc/rancher/rke2/config.yaml
on the control plane node and set the --audit-log-maxbackup parameter to an appropriate value.
For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "audit-log-maxbackup=15"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_19_ensure_that_the_audit_log_maxsize_argument_is_set_to_100_or_as_appropriate_automated"><a class="anchor" href="#_1_2_19_ensure_that_the_audit_log_maxsize_argument_is_set_to_100_or_as_appropriate_automated"></a>1.2.19 Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--audit-log-maxsize' is greater or equal to 100</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --audit-log-maxsize argument to 100 MB.
If you want to change this, edit the RKE2 config file /etc/rancher/rke2/config.yaml
on the control plane node and set the --audit-log-maxsize parameter to an appropriate size in MB.
For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "audit-log-maxsize=150"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_20_ensure_that_the_request_timeout_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_20_ensure_that_the_request_timeout_argument_is_set_as_appropriate_automated"></a>1.2.20 Ensure that the --request-timeout argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--request-timeout' is not present OR '--request-timeout' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Permissive, per CIS guidelines,
"it is recommended to set this limit as appropriate and change the default limit of 60 seconds only if needed".
Edit the RKE2 config file /etc/rancher/rke2/config.yaml
and set the below parameter if needed. For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "request-timeout=300s"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_21_ensure_that_the_service_account_lookup_argument_is_set_to_true_automated"><a class="anchor" href="#_1_2_21_ensure_that_the_service_account_lookup_argument_is_set_to_true_automated"></a>1.2.21 Ensure that the --service-account-lookup argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--service-account-lookup' is not present OR '--service-account-lookup' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --service-account-lookup argument.
Edit the RKE2 config file /etc/rancher/rke2/config.yaml and set the service-account-lookup. For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "service-account-lookup=true"</pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can delete the service-account-lookup parameter from this file so
that the default takes effect.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_22_ensure_that_the_service_account_key_file_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_22_ensure_that_the_service_account_key_file_argument_is_set_as_appropriate_automated"></a>1.2.22 Ensure that the --service-account-key-file argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--service-account-key-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>RKE2 automatically generates and sets the service account key file.
It is located at /var/lib/rancher/rke2/server/tls/service.key.
If this check fails, edit RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "service-account-key-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_23_ensure_that_the_etcd_certfile_and_etcd_keyfile_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_1_2_23_ensure_that_the_etcd_certfile_and_etcd_keyfile_arguments_are_set_as_appropriate_automated"></a>1.2.23 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--etcd-certfile' is present AND '--etcd-keyfile' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>RKE2 automatically generates and sets the etcd certificate and key files.
They are located at /var/lib/rancher/rke2/server/tls/etcd/client.crt and /var/lib/rancher/rke2/server/tls/etcd/client.key.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "etcd-certfile=&lt;path&gt;"
  - "etcd-keyfile=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_24_ensure_that_the_tls_cert_file_and_tls_private_key_file_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_1_2_24_ensure_that_the_tls_cert_file_and_tls_private_key_file_arguments_are_set_as_appropriate_automated"></a>1.2.24 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--tls-cert-file' is present AND '--tls-private-key-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically generates and provides the TLS certificate and private key for the apiserver.
They are generated and located at /var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt and /var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "tls-cert-file=&lt;path&gt;"
  - "tls-private-key-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_25_ensure_that_the_client_ca_file_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_25_ensure_that_the_client_ca_file_argument_is_set_as_appropriate_automated"></a>1.2.25 Ensure that the --client-ca-file argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--client-ca-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the client certificate authority file.
It is generated and located at /var/lib/rancher/rke2/server/tls/client-ca.crt.
If for some reason you need to provide your own ca certificate, look at using the rke2 certificate command line tool.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "client-ca-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_26_ensure_that_the_etcd_cafile_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_26_ensure_that_the_etcd_cafile_argument_is_set_as_appropriate_automated"></a>1.2.26 Ensure that the --etcd-cafile argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--etcd-cafile' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the etcd certificate authority file.
It is generated and located at /var/lib/rancher/rke2/server/tls/client-ca.crt.
If for some reason you need to provide your own ca certificate, look at using the rke2 certificate command line tool.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-apiserver-arg:
  - "etcd-cafile=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_27_ensure_that_the_encryption_provider_config_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_2_27_ensure_that_the_encryption_provider_config_argument_is_set_as_appropriate_automated"></a>1.2.27 Ensure that the --encryption-provider-config argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--encryption-provider-config' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>RKE2 always is configured to encrypt secrets.
Secrets encryption is managed with the rke2 secrets-encrypt command line tool.
If needed, you can find the generated encryption config at /var/lib/rancher/rke2/server/cred/encryption-config.json</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_28_ensure_that_encryption_providers_are_appropriately_configured_automated"><a class="anchor" href="#_1_2_28_ensure_that_encryption_providers_are_appropriately_configured_automated"></a>1.2.28 Ensure that encryption providers are appropriately configured (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ENCRYPTION_PROVIDER_CONFIG=$(ps -ef | grep kube-apiserver | grep -- --encryption-provider-config | sed 's%.*encryption-provider-config[= ]\([^ ]*\).*%\1%')
if test -e $ENCRYPTION_PROVIDER_CONFIG; then grep -o 'providers\"\:\[.*\]' $ENCRYPTION_PROVIDER_CONFIG | grep -o "[A-Za-z]*" | head -2 | tail -1  | sed 's/^/provider=/'; fi</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'provider' contains valid elements from 'aescbc,kms,secretbox'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">provider=aescbc</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>RKE2 always is configured to use the aescbc encryption provider to encrypt secrets.
Secrets encryption is managed with the rke2 secrets-encrypt command line tool.
If needed, you can find the generated encryption config at /var/lib/rancher/rke2/server/cred/encryption-config.json</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_2_29_ensure_that_the_api_server_only_makes_use_of_strong_cryptographic_ciphers_automated"><a class="anchor" href="#_1_2_29_ensure_that_the_api_server_only_makes_use_of_strong_cryptographic_ciphers_automated"></a>1.2.29 Ensure that the API Server only makes use of Strong Cryptographic Ciphers (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-apiserver</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--tls-cipher-suites' contains valid elements from 'TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_GCM_SHA384'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, the RKE2 kube-apiserver complies with this test. Changes to these values may cause regression, therefore ensure that all apiserver clients support the new TLS configuration before applying it in production deployments.
If a custom TLS configuration is required, consider also creating a custom version of this rule that aligns with your requirements.
If this check fails, remove any custom configuration around <code>tls-cipher-suites</code> or update the /etc/rancher/rke2/config.yaml file to match the default by adding the following:
kube-apiserver-arg:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>"tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305"</p>
</li>
</ul>
</div>
</div>
</details>
</div>
</div>
<div class="sect2">
<h3 id="_1_3_controller_manager"><a class="anchor" href="#_1_3_controller_manager"></a>1.3 Controller Manager</h3>
<div class="sect3">
<h4 id="_1_3_1_ensure_that_the_terminated_pod_gc_threshold_argument_is_set_as_appropriate_manual"><a class="anchor" href="#_1_3_1_ensure_that_the_terminated_pod_gc_threshold_argument_is_set_as_appropriate_manual"></a>1.3.1 Ensure that the --terminated-pod-gc-threshold argument is set as appropriate (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--terminated-pod-gc-threshold' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets a terminated-pod-gc-threshold of 1000.
If you need to change this value, edit the RKE2 config file /etc/rancher/rke2/config.yaml on the control plane node
and set the --terminated-pod-gc-threshold to an appropriate threshold,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "terminated-pod-gc-threshold=10"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_2_ensure_that_the_profiling_argument_is_set_to_false_automated"><a class="anchor" href="#_1_3_2_ensure_that_the_profiling_argument_is_set_to_false_automated"></a>1.3.2 Ensure that the --profiling argument is set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--profiling' is equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --profiling argument to false.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "profiling=true"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_3_ensure_that_the_use_service_account_credentials_argument_is_set_to_true_automated"><a class="anchor" href="#_1_3_3_ensure_that_the_use_service_account_credentials_argument_is_set_to_true_automated"></a>1.3.3 Ensure that the --use-service-account-credentials argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--use-service-account-credentials' is not equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --use-service-account-credentials argument to true.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "use-service-account-credentials=false"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_4_ensure_that_the_service_account_private_key_file_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_3_4_ensure_that_the_service_account_private_key_file_argument_is_set_as_appropriate_automated"></a>1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--service-account-private-key-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the service account private key file.
It is generated and located at /var/lib/rancher/rke2/server/tls/service.current.key.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "service-account-private-key-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_5_ensure_that_the_root_ca_file_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_1_3_5_ensure_that_the_root_ca_file_argument_is_set_as_appropriate_automated"></a>1.3.5 Ensure that the --root-ca-file argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--root-ca-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the root CA file.
It is generated and located at /var/lib/rancher/rke2/server/tls/server-ca.crt.
If for some reason you need to provide your own ca certificate, look at using the rke2 certificate command line tool.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "root-ca-file=&lt;path&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_6_ensure_that_the_rotatekubeletservercertificate_argument_is_set_to_true_automated"><a class="anchor" href="#_1_3_6_ensure_that_the_rotatekubeletservercertificate_argument_is_set_to_true_automated"></a>1.3.6 Ensure that the RotateKubeletServerCertificate argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--feature-gates' is present OR '--feature-gates' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the RotateKubeletServerCertificate feature gate.
If you have enabled this feature gate, you should remove it.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "feature-gate=RotateKubeletServerCertificate"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_3_7_ensure_that_the_bind_address_argument_is_set_to_127_0_0_1_automated"><a class="anchor" href="#_1_3_7_ensure_that_the_bind_address_argument_is_set_to_127_0_0_1_automated"></a>1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-controller-manager</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--bind-address' is equal to '127.0.0.1' OR '--bind-address' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --bind-address argument to 127.0.0.1
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-controller-manager-arg:
  - "bind-address=&lt;IP&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
</div>
<div class="sect2">
<h3 id="_1_4_scheduler"><a class="anchor" href="#_1_4_scheduler"></a>1.4 Scheduler</h3>
<div class="sect3">
<h4 id="_1_4_1_ensure_that_the_profiling_argument_is_set_to_false_automated"><a class="anchor" href="#_1_4_1_ensure_that_the_profiling_argument_is_set_to_false_automated"></a>1.4.1 Ensure that the --profiling argument is set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-scheduler</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--profiling' is equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2905    2804  0 17:46 ?        00:00:00 kube-scheduler --permit-port-sharing=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --profiling=false --secure-port=10259</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --profiling argument to false.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-scheduler-arg:
  - "profiling=true"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_1_4_2_ensure_that_the_bind_address_argument_is_set_to_127_0_0_1_automated"><a class="anchor" href="#_1_4_2_ensure_that_the_bind_address_argument_is_set_to_127_0_0_1_automated"></a>1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1 (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -fC kube-scheduler</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--bind-address' is equal to '127.0.0.1' OR '--bind-address' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2905    2804  0 17:46 ?        00:00:00 kube-scheduler --permit-port-sharing=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/rke2/server/cred/scheduler.kubeconfig --profiling=false --secure-port=10259</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --bind-address argument to 127.0.0.1
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines like below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kube-scheduler-arg:
  - "bind-address=&lt;IP&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_etcd_node_configuration"><a class="anchor" href="#_2_etcd_node_configuration"></a>2 Etcd Node Configuration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_etcd_node_configuration_2"><a class="anchor" href="#_2_etcd_node_configuration_2"></a>2 Etcd Node Configuration</h3>
<div class="sect3">
<h4 id="_2_1_ensure_that_the_cert_file_and_key_file_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_2_1_ensure_that_the_cert_file_and_key_file_arguments_are_set_as_appropriate_automated"></a>2.1 Ensure that the --cert-file and --key-file arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '.client-transport-security.cert-file' is equal to '/var/lib/rancher/rke2/server/tls/etcd/server-client.crt' AND '.client-transport-security.key-file' is equal to '/var/lib/rancher/rke2/server/tls/etcd/server-client.key'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">advertise-client-urls: https://10.10.10.100:2379
client-transport-security:
  cert-file: /var/lib/rancher/rke2/server/tls/etcd/server-client.crt
  client-cert-auth: true
  key-file: /var/lib/rancher/rke2/server/tls/etcd/server-client.key
  trusted-ca-file: /var/lib/rancher/rke2/server/tls/etcd/server-ca.crt
data-dir: /var/lib/rancher/rke2/server/db/etcd
election-timeout: 5000
experimental-initial-corrupt-check: true
experimental-watch-progress-notify-interval: 5000000000
heartbeat-interval: 500
initial-advertise-peer-urls: https://10.10.10.100:2380
initial-cluster: server-0-c121eac1=https://10.10.10.100:2380
initial-cluster-state: new
listen-client-http-urls: https://127.0.0.1:2382
listen-client-urls: https://127.0.0.1:2379,https://10.10.10.100:2379
listen-metrics-urls: http://127.0.0.1:2381
listen-peer-urls: https://127.0.0.1:2380,https://10.10.10.100:2380
log-outputs:
- stderr
logger: zap
name: server-0-c121eac1
peer-transport-security:
  cert-file: /var/lib/rancher/rke2/server/tls/etcd/peer-server-client.crt
  client-cert-auth: true
  key-file: /var/lib/rancher/rke2/server/tls/etcd/peer-server-client.key
  trusted-ca-file: /var/lib/rancher/rke2/server/tls/etcd/peer-ca.crt
snapshot-count: 10000</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 generates cert and key files for etcd.
These are located in /var/lib/rancher/rke2/server/tls/etcd/.
If this check fails, ensure that the configuration file /var/lib/rancher/rke2/server/db/etcd/config
has not been modified to use custom cert and key files.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_2_ensure_that_the_client_cert_auth_argument_is_set_to_true_automated"><a class="anchor" href="#_2_2_ensure_that_the_client_cert_auth_argument_is_set_to_true_automated"></a>2.2 Ensure that the --client-cert-auth argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'ETCD_CLIENT_CERT_AUTH' is present OR '.client-transport-security.client-cert-auth' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=server-0
ETCD_UNSUPPORTED_ARCH=
FILE_HASH=f216f1dc6126cfc7e5e05f8eb114a99a95856a165eca7b65504063b939c7f9b6
NO_PROXY=.svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
HOME=/</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --client-cert-auth parameter to true.
If this check fails, ensure that the configuration file /var/lib/rancher/rke2/server/db/etcd/config
has not been modified to disable client certificate authentication.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_3_ensure_that_the_auto_tls_argument_is_not_set_to_true_automated"><a class="anchor" href="#_2_3_ensure_that_the_auto_tls_argument_is_not_set_to_true_automated"></a>2.3 Ensure that the --auto-tls argument is not set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'ETCD_AUTO_TLS' is not present OR 'ETCD_AUTO_TLS' is present OR '.client-transport-security.auto-tls' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=server-0
ETCD_UNSUPPORTED_ARCH=
FILE_HASH=f216f1dc6126cfc7e5e05f8eb114a99a95856a165eca7b65504063b939c7f9b6
NO_PROXY=.svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
HOME=/</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --auto-tls parameter.
If this check fails, edit the etcd pod specification file /var/lib/rancher/rke2/server/db/etcd/config on the master
node and either remove the --auto-tls parameter or set it to false.
client-transport-security:
  auto-tls: false</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_4_ensure_that_the_peer_cert_file_and_peer_key_file_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_2_4_ensure_that_the_peer_cert_file_and_peer_key_file_arguments_are_set_as_appropriate_automated"></a>2.4 Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '.peer-transport-security.cert-file' is equal to '/var/lib/rancher/rke2/server/tls/etcd/peer-server-client.crt' AND '.peer-transport-security.key-file' is equal to '/var/lib/rancher/rke2/server/tls/etcd/peer-server-client.key'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">advertise-client-urls: https://10.10.10.100:2379
client-transport-security:
  cert-file: /var/lib/rancher/rke2/server/tls/etcd/server-client.crt
  client-cert-auth: true
  key-file: /var/lib/rancher/rke2/server/tls/etcd/server-client.key
  trusted-ca-file: /var/lib/rancher/rke2/server/tls/etcd/server-ca.crt
data-dir: /var/lib/rancher/rke2/server/db/etcd
election-timeout: 5000
experimental-initial-corrupt-check: true
experimental-watch-progress-notify-interval: 5000000000
heartbeat-interval: 500
initial-advertise-peer-urls: https://10.10.10.100:2380
initial-cluster: server-0-c121eac1=https://10.10.10.100:2380
initial-cluster-state: new
listen-client-http-urls: https://127.0.0.1:2382
listen-client-urls: https://127.0.0.1:2379,https://10.10.10.100:2379
listen-metrics-urls: http://127.0.0.1:2381
listen-peer-urls: https://127.0.0.1:2380,https://10.10.10.100:2380
log-outputs:
- stderr
logger: zap
name: server-0-c121eac1
peer-transport-security:
  cert-file: /var/lib/rancher/rke2/server/tls/etcd/peer-server-client.crt
  client-cert-auth: true
  key-file: /var/lib/rancher/rke2/server/tls/etcd/peer-server-client.key
  trusted-ca-file: /var/lib/rancher/rke2/server/tls/etcd/peer-ca.crt
snapshot-count: 10000</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 generates peer cert and key files for etcd.
These are located in /var/lib/rancher/rke2/server/tls/etcd/.
If this check fails, ensure that the configuration file /var/lib/rancher/rke2/server/db/etcd/config
has not been modified to use custom peer cert and key files.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_5_ensure_that_the_peer_client_cert_auth_argument_is_set_to_true_automated"><a class="anchor" href="#_2_5_ensure_that_the_peer_client_cert_auth_argument_is_set_to_true_automated"></a>2.5 Ensure that the --peer-client-cert-auth argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'ETCD_PEER_CLIENT_CERT_AUTH' is present OR '.peer-transport-security.client-cert-auth' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=server-0
ETCD_UNSUPPORTED_ARCH=
FILE_HASH=f216f1dc6126cfc7e5e05f8eb114a99a95856a165eca7b65504063b939c7f9b6
NO_PROXY=.svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
HOME=/</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --peer-cert-auth parameter to true.
If this check fails, ensure that the configuration file /var/lib/rancher/rke2/server/db/etcd/config
has not been modified to disable peer client certificate authentication.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_6_ensure_that_the_peer_auto_tls_argument_is_not_set_to_true_automated"><a class="anchor" href="#_2_6_ensure_that_the_peer_auto_tls_argument_is_not_set_to_true_automated"></a>2.6 Ensure that the --peer-auto-tls argument is not set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'ETCD_PEER_AUTO_TLS' is not present OR 'ETCD_PEER_AUTO_TLS' is present OR '.peer-transport-security.auto-tls' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=server-0
ETCD_UNSUPPORTED_ARCH=
FILE_HASH=f216f1dc6126cfc7e5e05f8eb114a99a95856a165eca7b65504063b939c7f9b6
NO_PROXY=.svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
HOME=/</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --peer-auto-tls parameter.
If this check fails, edit the etcd pod specification file /var/lib/rancher/rke2/server/db/etcd/config on the master
node and either remove the --peer-auto-tls parameter or set it to false.
peer-transport-security:
  auto-tls: false</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_2_7_ensure_that_a_unique_certificate_authority_is_used_for_etcd_automated"><a class="anchor" href="#_2_7_ensure_that_a_unique_certificate_authority_is_used_for_etcd_automated"></a>2.7 Ensure that a unique Certificate Authority is used for etcd (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">cat /var/lib/rancher/rke2/server/db/etcd/config</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'ETCD_TRUSTED_CA_FILE' is present OR '.peer-transport-security.trusted-ca-file' is equal to '/var/lib/rancher/rke2/server/tls/etcd/peer-ca.crt'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=server-0
ETCD_UNSUPPORTED_ARCH=
FILE_HASH=f216f1dc6126cfc7e5e05f8eb114a99a95856a165eca7b65504063b939c7f9b6
NO_PROXY=.svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
HOME=/</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 generates a unique certificate authority for etcd.
This is located at /var/lib/rancher/rke2/server/tls/etcd/peer-ca.crt.
If this check fails, ensure that the configuration file /var/lib/rancher/rke2/server/db/etcd/config
has not been modified to use a shared certificate authority.</p>
</div>
</div>
</details>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_3_control_plane_configuration"><a class="anchor" href="#_3_control_plane_configuration"></a>3 Control Plane Configuration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_authentication_and_authorization"><a class="anchor" href="#_3_1_authentication_and_authorization"></a>3.1 Authentication and Authorization</h3>
<div class="sect3">
<h4 id="_3_1_1_client_certificate_authentication_should_not_be_used_for_users_manual"><a class="anchor" href="#_3_1_1_client_certificate_authentication_should_not_be_used_for_users_manual"></a>3.1.1 Client certificate authentication should not be used for users (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Alternative mechanisms provided by Kubernetes such as the use of OIDC should be
implemented in place of client certificates.</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_2_service_account_token_authentication_should_not_be_used_for_users_manual"><a class="anchor" href="#_3_1_2_service_account_token_authentication_should_not_be_used_for_users_manual"></a>3.1.2 Service account token authentication should not be used for users (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented
in place of service account tokens.</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_1_3_bootstrap_token_authentication_should_not_be_used_for_users_manual"><a class="anchor" href="#_3_1_3_bootstrap_token_authentication_should_not_be_used_for_users_manual"></a>3.1.3 Bootstrap token authentication should not be used for users (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented
in place of bootstrap tokens.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_2_logging"><a class="anchor" href="#_3_2_logging"></a>3.2 Logging</h3>
<div class="sect3">
<h4 id="_3_2_1_ensure_that_a_minimal_audit_policy_is_created_automated"><a class="anchor" href="#_3_2_1_ensure_that_a_minimal_audit_policy_is_created_automated"></a>3.2.1 Ensure that a minimal audit policy is created (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/ps -ef | grep kube-apiserver | grep -v grep</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--audit-policy-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root        2617    2565  8 17:46 ?        00:00:14 kube-apiserver --admission-control-config-file=/etc/rancher/rke2/rke2-pss.yaml --audit-policy-file=/etc/rancher/rke2/audit-policy.yaml --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --audit-log-path=/var/lib/rancher/rke2/server/logs/audit.log --advertise-address=10.10.10.100 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,rke2 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --cert-dir=/var/lib/rancher/rke2/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/rke2/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/rke2/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --encryption-provider-config=/var/lib/rancher/rke2/server/cred/encryption-config.json --encryption-provider-config-automatic-reload=true --etcd-cafile=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt --etcd-certfile=/var/lib/rancher/rke2/server/tls/etcd/client.crt --etcd-keyfile=/var/lib/rancher/rke2/server/tls/etcd/client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-certificate-authority=/var/lib/rancher/rke2/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/rke2/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/rke2/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/rke2/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/rke2/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/rke2/server/tls/serving-kube-apiserver.key
root        2890    2785  1 17:46 ?        00:00:02 kube-controller-manager --flex-volume-plugin-dir=/var/lib/kubelet/volumeplugins --terminated-pod-gc-threshold=1000 --permit-port-sharing=true --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/rke2/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/rke2/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/rke2/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/rke2/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/rke2/server/cred/controller.kubeconfig --profiling=false --root-ca-file=/var/lib/rancher/rke2/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/rke2/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Create an audit policy file for your cluster.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_3_2_2_ensure_that_the_audit_policy_covers_key_security_concerns_manual"><a class="anchor" href="#_3_2_2_ensure_that_the_audit_policy_covers_key_security_concerns_manual"></a>3.2.2 Ensure that the audit policy covers key security concerns (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Review the audit policy provided for the cluster and ensure that it covers
at least the following areas,</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Access to Secrets managed by the cluster. Care should be taken to only
log Metadata for requests to Secrets, ConfigMaps, and TokenReviews, in
order to avoid risk of logging sensitive data.</p>
</li>
<li>
<p>Modification of Pod and Deployment objects.</p>
</li>
<li>
<p>Use of <code>pods/exec</code>, <code>pods/portforward</code>, <code>pods/proxy</code> and <code>services/proxy</code>.
For most requests, minimally logging at the Metadata level is recommended
(the most basic level of logging).</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_4_worker_node_security_configuration"><a class="anchor" href="#_4_worker_node_security_configuration"></a>4 Worker Node Security Configuration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_4_1_worker_node_configuration_files"><a class="anchor" href="#_4_1_worker_node_configuration_files"></a>4.1 Worker Node Configuration Files</h3>
<div class="sect3">
<h4 id="_4_1_1_ensure_that_the_kubelet_service_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_4_1_1_ensure_that_the_kubelet_service_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>4.1.1 Ensure that the kubelet service file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> Not Applicable</p>
</div>
<div class="paragraph">
<p><strong>Rationale:</strong></p>
</div>
<div class="paragraph">
<p>The kubelet is managed by the RKE2 process. There is no kubelet service file, all configuration is passed in as arguments at runtime.</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_2_ensure_that_the_kubelet_service_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_4_1_2_ensure_that_the_kubelet_service_file_ownership_is_set_to_rootroot_automated"></a>4.1.2 Ensure that the kubelet service file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> Not Applicable</p>
</div>
<div class="paragraph">
<p><strong>Rationale:</strong></p>
</div>
<div class="paragraph">
<p>The kubelet is managed by the RKE2 process. There is no kubelet service file, all configuration is passed in as arguments at runtime.</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_3_if_proxy_kubeconfig_file_exists_ensure_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_4_1_3_if_proxy_kubeconfig_file_exists_ensure_permissions_are_set_to_600_or_more_restrictive_automated"></a>4.1.3 If proxy kubeconfig file exists ensure permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig; then stat -c permissions=%a /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the each worker node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_4_if_proxy_kubeconfig_file_exists_ensure_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_4_1_4_if_proxy_kubeconfig_file_exists_ensure_ownership_is_set_to_rootroot_automated"></a>4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig; then stat -c %U:%G /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the each worker node.
For example, <code>chown root:root /var/lib/rancher/rke2/agent/kubeproxy.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_5_ensure_that_the_kubeconfig_kubelet_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_4_1_5_ensure_that_the_kubeconfig_kubelet_conf_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>4.1.5 Ensure that the --kubeconfig kubelet.conf file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/kubelet.kubeconfig; then stat -c permissions=%a /var/lib/rancher/rke2/agent/kubelet.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the each worker node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/agent/kubelet.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_6_ensure_that_the_kubeconfig_kubelet_conf_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_4_1_6_ensure_that_the_kubeconfig_kubelet_conf_file_ownership_is_set_to_rootroot_automated"></a>4.1.6 Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/kubelet.kubeconfig; then stat -c %U:%G /var/lib/rancher/rke2/agent/kubelet.kubeconfig; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the each worker node.
For example,
<code>chown root:root /var/lib/rancher/rke2/agent/kubelet.kubeconfig</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_7_ensure_that_the_certificate_authorities_file_permissions_are_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_4_1_7_ensure_that_the_certificate_authorities_file_permissions_are_set_to_600_or_more_restrictive_automated"></a>4.1.7 Ensure that the certificate authorities file permissions are set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/client-ca.crt; then stat -c permissions=%a /var/lib/rancher/rke2/agent/client-ca.crt; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> permissions has permissions 600, expected 600 or more restrictive</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">permissions=600</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the below command (based on the file location on your system) on the each worker node.
For example,
<code>chmod 600 /var/lib/rancher/rke2/agent/client-ca.crt</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_8_ensure_that_the_client_certificate_authorities_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_4_1_8_ensure_that_the_client_certificate_authorities_file_ownership_is_set_to_rootroot_automated"></a>4.1.8 Ensure that the client certificate authorities file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /var/lib/rancher/rke2/agent/client-ca.crt; then stat -c %U:%G /var/lib/rancher/rke2/agent/client-ca.crt; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'root:root' is equal to 'root:root'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">root:root</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Run the following command to modify the ownership of the --client-ca-file.
<code>chown root:root /var/lib/rancher/rke2/agent/client-ca.crt</code></p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_1_9_if_the_kubelet_config_yaml_configuration_file_is_being_used_validate_permissions_set_to_600_or_more_restrictive_automated"><a class="anchor" href="#_4_1_9_if_the_kubelet_config_yaml_configuration_file_is_being_used_validate_permissions_set_to_600_or_more_restrictive_automated"></a>4.1.9 If the kubelet config.yaml configuration file is being used validate permissions set to 600 or more restrictive (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> Not Applicable</p>
</div>
<div class="paragraph">
<p><strong>Rationale:</strong></p>
</div>
<div class="paragraph">
<p>The kubelet is managed by the RKE2 process. There is no kubelet config file, all configuration is passed in as arguments at runtime.</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_1_10_if_the_kubelet_config_yaml_configuration_file_is_being_used_validate_file_ownership_is_set_to_rootroot_automated"><a class="anchor" href="#_4_1_10_if_the_kubelet_config_yaml_configuration_file_is_being_used_validate_file_ownership_is_set_to_rootroot_automated"></a>4.1.10 If the kubelet config.yaml configuration file is being used validate file ownership is set to root:root (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> Not Applicable</p>
</div>
<div class="paragraph">
<p><strong>Rationale:</strong></p>
</div>
<div class="paragraph">
<p>The kubelet is managed by the RKE2 process. There is no kubelet config file, all configuration is passed in as arguments at runtime.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_2_kubelet"><a class="anchor" href="#_4_2_kubelet"></a>4.2 Kubelet</h3>
<div class="sect3">
<h4 id="_4_2_1_ensure_that_the_anonymous_auth_argument_is_set_to_false_automated"><a class="anchor" href="#_4_2_1_ensure_that_the_anonymous_auth_argument_is_set_to_false_automated"></a>4.2.1 Ensure that the --anonymous-auth argument is set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--anonymous-auth' is equal to 'false'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --anonymous-auth to false.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "anonymous-auth=true"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_2_ensure_that_the_authorization_mode_argument_is_not_set_to_alwaysallow_automated"><a class="anchor" href="#_4_2_2_ensure_that_the_authorization_mode_argument_is_not_set_to_alwaysallow_automated"></a>4.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--authorization-mode' does not have 'AlwaysAllow'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --authorization-mode to AlwaysAllow.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "authorization-mode=AlwaysAllow"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_3_ensure_that_the_client_ca_file_argument_is_set_as_appropriate_automated"><a class="anchor" href="#_4_2_3_ensure_that_the_client_ca_file_argument_is_set_as_appropriate_automated"></a>4.2.3 Ensure that the --client-ca-file argument is set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--client-ca-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the client ca certificate for the Kubelet.
It is generated and located at /var/lib/rancher/rke2/agent/client-ca.crt</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_4_verify_that_the_read_only_port_argument_is_set_to_0_automated"><a class="anchor" href="#_4_2_4_verify_that_the_read_only_port_argument_is_set_to_0_automated"></a>4.2.4 Verify that the --read-only-port argument is set to 0 (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--read-only-port' is equal to '0' OR '--read-only-port' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 sets the --read-only-port to 0. If you have set this to a different value, you
should set it back to 0. Edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any lines similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "read-only-port=XXXX"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_5_ensure_that_the_streaming_connection_idle_timeout_argument_is_not_set_to_0_manual"><a class="anchor" href="#_4_2_5_ensure_that_the_streaming_connection_idle_timeout_argument_is_not_set_to_0_manual"></a>4.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--streaming-connection-idle-timeout' is present OR '--streaming-connection-idle-timeout' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Edit the RKE2 config file /etc/rancher/rke2/config.yaml, set the following parameter to an appropriate value.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "streaming-connection-idle-timeout=5m"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_6_ensure_that_the_make_iptables_util_chains_argument_is_set_to_true_automated"><a class="anchor" href="#_4_2_6_ensure_that_the_make_iptables_util_chains_argument_is_set_to_true_automated"></a>4.2.6 Ensure that the --make-iptables-util-chains argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--make-iptables-util-chains' is present OR '--make-iptables-util-chains' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Edit the RKE2 config file /etc/rancher/rke2/config.yaml, set the following parameter.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "make-iptables-util-chains=true"</pre>
</div>
</div>
<div class="paragraph">
<p>Or, remove the --make-iptables-util-chains argument to let RKE2 use the default value.
Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_7_ensure_that_the_hostname_override_argument_is_not_set_automated"><a class="anchor" href="#_4_2_7_ensure_that_the_hostname_override_argument_is_not_set_automated"></a>4.2.7 Ensure that the --hostname-override argument is not set (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> Not Applicable</p>
</div>
<div class="paragraph">
<p><strong>Rationale:</strong></p>
</div>
<div class="paragraph">
<p>By default, RKE2 does set the --hostname-override argument. Per CIS guidelines, this is to comply
with cloud providers that require this flag to ensure that hostname matches node names.</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_2_8_ensure_that_the_eventrecordqps_argument_is_set_to_a_level_which_ensures_appropriate_event_capture_manual"><a class="anchor" href="#_4_2_8_ensure_that_the_eventrecordqps_argument_is_set_to_a_level_which_ensures_appropriate_event_capture_manual"></a>4.2.8 Ensure that the eventRecordQPS argument is set to a level which ensures appropriate event capture (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--event-qps' is present OR '--event-qps' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Edit the RKE2 config file /etc/rancher/rke2/config.yaml, set the following parameter to an appropriate value.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "event-qps=&lt;value&gt;"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_9_ensure_that_the_tls_cert_file_and_tls_private_key_file_arguments_are_set_as_appropriate_automated"><a class="anchor" href="#_4_2_9_ensure_that_the_tls_cert_file_and_tls_private_key_file_arguments_are_set_as_appropriate_automated"></a>4.2.9 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--tls-cert-file' is present AND '--tls-private-key-file' is present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 automatically provides the TLS certificate and private key for the Kubelet.
They are generated and located at /var/lib/rancher/rke2/agent/serving-kubelet.crt and /var/lib/rancher/rke2/agent/serving-kubelet.key
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml and remove any lines similar to below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "tls-cert-file=&lt;path/to/tls-cert-file&gt;"
  - "tls-private-key-file=&lt;path/to/tls-private-key-file&gt;"</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_10_ensure_that_the_rotate_certificates_argument_is_not_set_to_false_automated"><a class="anchor" href="#_4_2_10_ensure_that_the_rotate_certificates_argument_is_not_set_to_false_automated"></a>4.2.10 Ensure that the --rotate-certificates argument is not set to false (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--rotate-certificates' is present OR '--rotate-certificates' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the --rotate-certificates argument.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any rotate-certificates parameter.
Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_11_verify_that_the_rotatekubeletservercertificate_argument_is_set_to_true_automated"><a class="anchor" href="#_4_2_11_verify_that_the_rotatekubeletservercertificate_argument_is_set_to_true_automated"></a>4.2.11 Verify that the RotateKubeletServerCertificate argument is set to true (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/cat /var/lib/kubelet/config.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'RotateKubeletServerCertificate' is present OR 'RotateKubeletServerCertificate' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2363    2330  2 17:46 ?        00:00:04 kubelet --volume-plugin-dir=/var/lib/kubelet/volumeplugins --file-check-frequency=5s --sync-frequency=30s --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/rke2/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available&lt;5%,nodefs.available&lt;5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubelet.kubeconfig --node-ip=10.10.10.100 --node-labels= --pod-infra-container-image=index.docker.io/rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/rke2/agent/pod-manifests --protect-kernel-defaults=true --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/rke2/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/rke2/agent/serving-kubelet.key</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>By default, RKE2 does not set the RotateKubeletServerCertificate feature gate.
If this check fails, edit the RKE2 config file /etc/rancher/rke2/config.yaml, remove any RotateKubeletServerCertificate parameter.
Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_4_2_12_ensure_that_the_kubelet_only_makes_use_of_strong_cryptographic_ciphers_manual"><a class="anchor" href="#_4_2_12_ensure_that_the_kubelet_only_makes_use_of_strong_cryptographic_ciphers_manual"></a>4.2.12 Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Edit the RKE2 config file /etc/rancher/rke2/config.yaml,</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305"</pre>
</div>
</div>
<div class="paragraph">
<p>or to a subset of these values.
Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_2_13_ensure_that_a_limit_is_set_on_pod_pids_manual"><a class="anchor" href="#_4_2_13_ensure_that_a_limit_is_set_on_pod_pids_manual"></a>4.2.13 Ensure that a limit is set on pod PIDs (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Edit the RKE2 config file /etc/rancher/rke2/config.yaml, set the following parameter to an appropriate value.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubelet-arg:
  - "pod-max-pids=&lt;value&gt;"</pre>
</div>
</div>
<div class="paragraph">
<p>Based on your system, restart the RKE2 service. For example,
systemctl restart rke2-server.service</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_3_kube_proxy"><a class="anchor" href="#_4_3_kube_proxy"></a>4.3 kube-proxy</h3>
<div class="sect3">
<h4 id="_4_3_1_ensure_that_the_kube_proxy_metrics_service_is_bound_to_localhost_automated"><a class="anchor" href="#_4_3_1_ensure_that_the_kube_proxy_metrics_service_is_bound_to_localhost_automated"></a>4.3.1 Ensure that the kube-proxy metrics service is bound to localhost (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">/bin/sh -c 'if test -e /etc/kubernetes/addons/kube-proxy-daemonset.yaml; then cat /etc/kubernetes/addons/kube-proxy-daemonset.yaml; fi'</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> '--metrics-bind-address' is present OR '--metrics-bind-address' is not present</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">UID          PID    PPID  C STIME TTY          TIME CMD
root        2507    2412  0 17:46 ?        00:00:00 kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=server-0 --kubeconfig=/var/lib/rancher/rke2/agent/kubeproxy.kubeconfig --proxy-mode=iptables</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Modify or remove any values which bind the metrics service to a non-localhost address.
The default value is 127.0.0.1:10249.</p>
</div>
</div>
</details>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_5_kubernetes_policies"><a class="anchor" href="#_5_kubernetes_policies"></a>5 Kubernetes Policies</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_rbac_and_service_accounts"><a class="anchor" href="#_5_1_rbac_and_service_accounts"></a>5.1 RBAC and Service Accounts</h3>
<div class="sect3">
<h4 id="_5_1_1_ensure_that_the_cluster_admin_role_is_only_used_where_required_automated"><a class="anchor" href="#_5_1_1_ensure_that_the_cluster_admin_role_is_only_used_where_required_automated"></a>5.1.1 Ensure that the cluster-admin role is only used where required (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get clusterrolebindings -o=custom-columns=ROLE:.roleRef.name,NAME:.metadata.name,SUBJECT:.subjects[*].name --no-headers |  grep cluster-admin</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Expected Result:</strong> 'cluster-admin' matched by regex expression 'cluster-admin</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">helm-kube-system-rke2-.*'</p></td>
</tr>
</tbody>
</table>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">cluster-admin                                          cluster-admin                                          system:masters
cluster-admin                                          helm-kube-system-rke2-canal                            helm-rke2-canal
cluster-admin                                          helm-kube-system-rke2-coredns                          helm-rke2-coredns
cluster-admin                                          helm-kube-system-rke2-ingress-nginx                    helm-rke2-ingress-nginx
cluster-admin                                          helm-kube-system-rke2-metrics-server                   helm-rke2-metrics-server
cluster-admin                                          helm-kube-system-rke2-snapshot-controller              helm-rke2-snapshot-controller
cluster-admin                                          helm-kube-system-rke2-snapshot-controller-crd          helm-rke2-snapshot-controller-crd
cluster-admin                                          helm-kube-system-rke2-snapshot-validation-webhook      helm-rke2-snapshot-validation-webhook</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Identify all clusterrolebindings to the cluster-admin role. Check if they are used and
if they need this role or if they could use a role with fewer privileges. RKE2 gives exceptions
to the helm-kube-system-rke2-* clusterrolebindings which handles the installation of all rke2 managed components.
Where possible, first bind users to a lower privileged role and then remove the
clusterrolebinding to the cluster-admin role:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kubectl delete clusterrolebinding [name]</pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_1_2_minimize_access_to_secrets_automated"><a class="anchor" href="#_5_1_2_minimize_access_to_secrets_automated"></a>5.1.2 Minimize access to secrets (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove get, list and watch access to Secret objects in the cluster.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_3_minimize_wildcard_use_in_roles_and_clusterroles_automated"><a class="anchor" href="#_5_1_3_minimize_wildcard_use_in_roles_and_clusterroles_automated"></a>5.1.3 Minimize wildcard use in Roles and ClusterRoles (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Check Roles
kubectl get roles --all-namespaces -o custom-columns=ROLE_NAMESPACE:.metadata.namespace,ROLE_NAME:.metadata.name --no-headers | while read -r role_namespace role_name
do
  role_rules=$(kubectl get role -n "${role_namespace}" "${role_name}" -o=json | jq -c '.rules')
  if echo "${role_rules}" | grep -q "\[\"\*\"\]"; then
    printf "**role_name: %-50s  role_namespace: %-25s role_rules: %s is_compliant: false\n" "${role_name}" "${role_namespace}" "${role_rules}"
  else
    printf "**role_name: %-50s role_namespace: %-25s is_compliant: true\n" "${role_name}" "${role_namespace}"
  fi;
done

cr_whitelist="cluster-admin rke2-cloud-controller-manager local-path-provisioner-role"
cr_whitelist="$cr_whitelist system:kube-controller-manager system:kubelet-api-admin system:controller:namespace-controller"
cr_whitelist="$cr_whitelist system:controller:disruption-controller system:controller:generic-garbage-collector"
cr_whitelist="$cr_whitelist system:controller:horizontal-pod-autoscaler system:controller:resourcequota-controller"
# Check ClusterRoles
kubectl get clusterroles -o custom-columns=CLUSTERROLE_NAME:.metadata.name --no-headers | while read -r clusterrole_name
do
  clusterrole_rules=$(kubectl get clusterrole "${clusterrole_name}" -o=json | jq -c '.rules')
  if echo "${cr_whitelist}" | grep -q "${clusterrole_name}"; then
    printf "**clusterrole_name: %-50s is_whitelist: true  is_compliant: true\n" "${clusterrole_name}"
  elif echo "${clusterrole_rules}" | grep -q "\[\"\*\"\]"; then
    echo "**clusterrole_name: ${clusterrole_name} clusterrole_rules: ${clusterrole_rules} is_compliant: false"
  else
    printf "**clusterrole_name: %-50s is_whitelist: false is_compliant: true\n" "${clusterrole_name}"
  fi;
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">**role_name: system:controller:bootstrap-signer                 role_namespace: kube-public               is_compliant: true
**role_name: extension-apiserver-authentication-reader          role_namespace: kube-system               is_compliant: true
**role_name: rke2-ingress-nginx                                 role_namespace: kube-system               is_compliant: true
**role_name: rke2-snapshot-controller                           role_namespace: kube-system               is_compliant: true
**role_name: system::leader-locking-kube-controller-manager     role_namespace: kube-system               is_compliant: true
**role_name: system::leader-locking-kube-scheduler              role_namespace: kube-system               is_compliant: true
**role_name: system:controller:bootstrap-signer                 role_namespace: kube-system               is_compliant: true
**role_name: system:controller:cloud-provider                   role_namespace: kube-system               is_compliant: true
**role_name: system:controller:token-cleaner                    role_namespace: kube-system               is_compliant: true
**clusterrole_name: admin                                              is_whitelist: true  is_compliant: true
**clusterrole_name: calico-node                                        is_whitelist: false is_compliant: true
**clusterrole_name: cluster-admin                                      is_whitelist: true  is_compliant: true
**clusterrole_name: edit                                               is_whitelist: false is_compliant: true
**clusterrole_name: flannel                                            is_whitelist: false is_compliant: true
**clusterrole_name: rke2-cloud-controller-manager                      is_whitelist: true  is_compliant: true
**clusterrole_name: rke2-coredns-rke2-coredns                          is_whitelist: false is_compliant: true
**clusterrole_name: rke2-coredns-rke2-coredns-autoscaler               is_whitelist: false is_compliant: true
**clusterrole_name: rke2-ingress-nginx                                 is_whitelist: false is_compliant: true
**clusterrole_name: rke2-snapshot-controller                           is_whitelist: false is_compliant: true
**clusterrole_name: rke2-snapshot-validation-webhook                   is_whitelist: false is_compliant: true
**clusterrole_name: system:aggregate-to-admin                          is_whitelist: false is_compliant: true
**clusterrole_name: system:aggregate-to-edit                           is_whitelist: false is_compliant: true
**clusterrole_name: system:aggregate-to-view                           is_whitelist: false is_compliant: true
**clusterrole_name: system:auth-delegator                              is_whitelist: false is_compliant: true
**clusterrole_name: system:basic-user                                  is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:certificatesigningrequests:nodeclient is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:kube-apiserver-client-approver is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:kube-apiserver-client-kubelet-approver is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:kubelet-serving-approver is_whitelist: false is_compliant: true
**clusterrole_name: system:certificates.k8s.io:legacy-unknown-approver is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:attachdetach-controller          is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:certificate-controller           is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:clusterrole-aggregation-controller is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:cronjob-controller               is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:daemon-set-controller            is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:deployment-controller            is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:disruption-controller            is_whitelist: true  is_compliant: true
**clusterrole_name: system:controller:endpoint-controller              is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:endpointslice-controller         is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:endpointslicemirroring-controller is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:ephemeral-volume-controller      is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:expand-controller                is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:generic-garbage-collector        is_whitelist: true  is_compliant: true
**clusterrole_name: system:controller:horizontal-pod-autoscaler        is_whitelist: true  is_compliant: true
**clusterrole_name: system:controller:job-controller                   is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:namespace-controller             is_whitelist: true  is_compliant: true
**clusterrole_name: system:controller:node-controller                  is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:persistent-volume-binder         is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:pod-garbage-collector            is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:pv-protection-controller         is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:pvc-protection-controller        is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:replicaset-controller            is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:replication-controller           is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:resourcequota-controller         is_whitelist: true  is_compliant: true
**clusterrole_name: system:controller:root-ca-cert-publisher           is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:route-controller                 is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:service-account-controller       is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:service-controller               is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:statefulset-controller           is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:ttl-after-finished-controller    is_whitelist: false is_compliant: true
**clusterrole_name: system:controller:ttl-controller                   is_whitelist: false is_compliant: true
**clusterrole_name: system:discovery                                   is_whitelist: false is_compliant: true
**clusterrole_name: system:heapster                                    is_whitelist: false is_compliant: true
**clusterrole_name: system:kube-aggregator                             is_whitelist: false is_compliant: true
**clusterrole_name: system:kube-controller-manager                     is_whitelist: true  is_compliant: true
**clusterrole_name: system:kube-dns                                    is_whitelist: false is_compliant: true
**clusterrole_name: system:kube-proxy                                  is_whitelist: false is_compliant: true
**clusterrole_name: system:kube-scheduler                              is_whitelist: false is_compliant: true
**clusterrole_name: system:kubelet-api-admin                           is_whitelist: true  is_compliant: true
**clusterrole_name: system:monitoring                                  is_whitelist: false is_compliant: true
**clusterrole_name: system:node                                        is_whitelist: false is_compliant: true
**clusterrole_name: system:node-bootstrapper                           is_whitelist: false is_compliant: true
**clusterrole_name: system:node-problem-detector                       is_whitelist: false is_compliant: true
**clusterrole_name: system:node-proxier                                is_whitelist: false is_compliant: true
**clusterrole_name: system:persistent-volume-provisioner               is_whitelist: false is_compliant: true
**clusterrole_name: system:public-info-viewer                          is_whitelist: false is_compliant: true
**clusterrole_name: system:rke2-controller                             is_whitelist: false is_compliant: true
**clusterrole_name: system:rke2-metrics-server                         is_whitelist: false is_compliant: true
**clusterrole_name: system:rke2-metrics-server-aggregated-reader       is_whitelist: false is_compliant: true
**clusterrole_name: system:service-account-issuer-discovery            is_whitelist: false is_compliant: true
**clusterrole_name: system:volume-scheduler                            is_whitelist: false is_compliant: true
**clusterrole_name: view                                               is_whitelist: false is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Where possible replace any use of wildcards in clusterroles and roles with specific objects or actions.
RKE2 gives exceptions for following cluster roles, which are required for regular operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>rke2-cloud-controller-manager, local-path-provisioner-role, cluster-admin</p>
</li>
<li>
<p>system:kube-controller-manager, system:kubelet-api-admin, system:controller:namespace-controller,</p>
</li>
<li>
<p>system:controller:disruption-controller, system:controller:generic-garbage-collector,</p>
</li>
<li>
<p>system:controller:horizontal-pod-autoscaler, system:controller:resourcequota-controller</p>
</li>
</ul>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_1_4_minimize_access_to_create_pods_automated"><a class="anchor" href="#_5_1_4_minimize_access_to_create_pods_automated"></a>5.1.4 Minimize access to create pods (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove create access to pod objects in the cluster.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_5_ensure_that_default_service_accounts_are_not_actively_used_automated"><a class="anchor" href="#_5_1_5_ensure_that_default_service_accounts_are_not_actively_used_automated"></a>5.1.5 Ensure that default service accounts are not actively used. (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get serviceaccounts --all-namespaces --field-selector metadata.name=default \
-o custom-columns=N:.metadata.namespace,SA:.metadata.name,ASA:.automountServiceAccountToken --no-headers \
| while read -r namespace serviceaccount automountserviceaccounttoken
do
  if [ "${automountserviceaccounttoken}" = "&lt;none&gt;" ]; then
    automountserviceaccounttoken="notset"
  fi
  if [ "${namespace}" != "kube-system" ] &amp;&amp; [ "${automountserviceaccounttoken}" != "false" ]; then
    printf "**namespace: %-20s service_account: %-10s automountServiceAccountToken: %-6s is_compliant: false\n" "${namespace}" "${serviceaccount}" "${automountserviceaccounttoken}"
  else
    printf "**namespace: %-20s service_account: %-10s automountServiceAccountToken: %-6s is_compliant: true\n" "${namespace}" "${serviceaccount}" "${automountserviceaccounttoken}"
  fi
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">**namespace: default              service_account: default    automountServiceAccountToken: false  is_compliant: true
**namespace: kube-node-lease      service_account: default    automountServiceAccountToken: false  is_compliant: true
**namespace: kube-public          service_account: default    automountServiceAccountToken: false  is_compliant: true
**namespace: kube-system          service_account: default    automountServiceAccountToken: false  is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Create explicit service accounts wherever a Kubernetes workload requires specific access
to the Kubernetes API server.
Modify the configuration of each default service account to include this value
automountServiceAccountToken: false
Or using kubectl:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl patch serviceaccount --namespace &lt;NAMESPACE&gt;lt;NAMESPACE&lt;NAMESPACE&gt;gt; default --patch '{"automountServiceAccountToken": false}'</code></pre>
</div>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_1_6_ensure_that_service_account_tokens_are_only_mounted_where_necessary_automated"><a class="anchor" href="#_5_1_6_ensure_that_service_account_tokens_are_only_mounted_where_necessary_automated"></a>5.1.6 Ensure that Service Account Tokens are only mounted where necessary (Automated)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get pods --all-namespaces -o custom-columns=POD_NAMESPACE:.metadata.namespace,POD_NAME:.metadata.name,POD_SERVICE_ACCOUNT:.spec.serviceAccount,POD_IS_AUTOMOUNTSERVICEACCOUNTTOKEN:.spec.automountServiceAccountToken --no-headers | while read -r pod_namespace pod_name pod_service_account pod_is_automountserviceaccounttoken
do
  # Skip pods with no service account
  if [ "${pod_service_account}" = "&lt;none&gt;" ]; then
    continue
  fi
  # Retrieve automountServiceAccountToken's value for ServiceAccount and Pod, set to notset if null or &lt;none&gt;.
  svacc_is_automountserviceaccounttoken=$(kubectl get serviceaccount -n "${pod_namespace}" "${pod_service_account}" -o json | jq -r '.automountServiceAccountToken' | sed -e 's/&lt;none&gt;/notset/g' -e 's/null/notset/g')
  pod_is_automountserviceaccounttoken=$(echo "${pod_is_automountserviceaccounttoken}" | sed -e 's/&lt;none&gt;/notset/g' -e 's/null/notset/g')
  if [ "${svacc_is_automountserviceaccounttoken}" = "false" ] &amp;&amp; ( [ "${pod_is_automountserviceaccounttoken}" = "false" ] || [ "${pod_is_automountserviceaccounttoken}" = "notset" ] ); then
    is_compliant="true"
  elif [ "${svacc_is_automountserviceaccounttoken}" = "true" ] &amp;&amp; [ "${pod_is_automountserviceaccounttoken}" = "false" ]; then
    is_compliant="true"
  else
    is_compliant="false"
  fi
  # Whitelist kube-system namespace as these pods are expected to contact the apiserver
  if [ "${pod_namespace}" = "kube-system" ]; then
    is_compliant="true"
  fi
  echo "**namespace: ${pod_namespace} pod_name: ${pod_name} service_account: ${pod_service_account} pod_is_automountserviceaccounttoken: ${pod_is_automountserviceaccounttoken} svacc_is_automountServiceAccountToken: ${svacc_is_automountserviceaccounttoken} is_compliant: ${is_compliant}"
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">**namespace: kube-system pod_name: helm-install-rke2-canal-9n9dk service_account: helm-rke2-canal pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-coredns-8tv2t service_account: helm-rke2-coredns pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-ingress-nginx-nlmrr service_account: helm-rke2-ingress-nginx pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-metrics-server-n99w4 service_account: helm-rke2-metrics-server pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr service_account: helm-rke2-snapshot-controller-crd pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-snapshot-controller-shqn6 service_account: helm-rke2-snapshot-controller pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n service_account: helm-rke2-snapshot-validation-webhook pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: rke2-canal-b8l4s service_account: canal pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true
**namespace: kube-system pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk service_account: coredns pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true
**namespace: kube-system pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf service_account: rke2-coredns-rke2-coredns-autoscaler pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true
**namespace: kube-system pod_name: rke2-ingress-nginx-controller-wqq4m service_account: rke2-ingress-nginx pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: true is_compliant: true
**namespace: kube-system pod_name: rke2-metrics-server-7694cf7d77-rv9qh service_account: rke2-metrics-server pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true
**namespace: kube-system pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw service_account: rke2-snapshot-controller pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true
**namespace: kube-system pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 service_account: rke2-snapshot-validation-webhook pod_is_automountserviceaccounttoken: notset svacc_is_automountServiceAccountToken: notset is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Modify the definition of ServiceAccounts and Pods which do not need to mount service
account tokens to disable it, with <code>automountServiceAccountToken: false</code>.
RKE2 gives exceptions to the ServiceAccounts in kube-system namespace, as these are expected contact the apiserver.
When in cis mode, RKE2 disables the automountServiceAccountToken for namespaces:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>kube-public, default, kube-node-lease
If both the ServiceAccount and the Pod&#8217;s .spec specify a value for automountServiceAccountToken, the Pod spec takes precedence.
Condition: Pod is_compliant to true when</p>
<div class="ulist">
<ul>
<li>
<p>ServiceAccount is automountServiceAccountToken: false and Pod is automountServiceAccountToken: false or notset</p>
</li>
<li>
<p>ServiceAccount is automountServiceAccountToken: true/notset and Pod is automountServiceAccountToken: false</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_1_7_avoid_use_of_systemmasters_group_manual"><a class="anchor" href="#_5_1_7_avoid_use_of_systemmasters_group_manual"></a>5.1.7 Avoid use of system:masters group (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Remove the system:masters group from all users in the cluster.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_8_limit_use_of_the_bind_impersonate_and_escalate_permissions_in_the_kubernetes_cluster_manual"><a class="anchor" href="#_5_1_8_limit_use_of_the_bind_impersonate_and_escalate_permissions_in_the_kubernetes_cluster_manual"></a>5.1.8 Limit use of the Bind, Impersonate and Escalate permissions in the Kubernetes cluster (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove the impersonate, bind and escalate rights from subjects.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_9_minimize_access_to_create_persistent_volumes_manual"><a class="anchor" href="#_5_1_9_minimize_access_to_create_persistent_volumes_manual"></a>5.1.9 Minimize access to create persistent volumes (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove create access to PersistentVolume objects in the cluster.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_10_minimize_access_to_the_proxy_sub_resource_of_nodes_manual"><a class="anchor" href="#_5_1_10_minimize_access_to_the_proxy_sub_resource_of_nodes_manual"></a>5.1.10 Minimize access to the proxy sub-resource of nodes (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove access to the proxy sub-resource of node objects.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_11_minimize_access_to_the_approval_sub_resource_of_certificatesigningrequests_objects_manual"><a class="anchor" href="#_5_1_11_minimize_access_to_the_approval_sub_resource_of_certificatesigningrequests_objects_manual"></a>5.1.11 Minimize access to the approval sub-resource of certificatesigningrequests objects (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove access to the approval sub-resource of certificatesigningrequests objects.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_12_minimize_access_to_webhook_configuration_objects_manual"><a class="anchor" href="#_5_1_12_minimize_access_to_webhook_configuration_objects_manual"></a>5.1.12 Minimize access to webhook configuration objects (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove access to the validatingwebhookconfigurations or mutatingwebhookconfigurations objects</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_1_13_minimize_access_to_the_service_account_token_creation_manual"><a class="anchor" href="#_5_1_13_minimize_access_to_the_service_account_token_creation_manual"></a>5.1.13 Minimize access to the service account token creation (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Where possible, remove access to the token sub-resource of serviceaccount objects.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_pod_security_standards"><a class="anchor" href="#_5_2_pod_security_standards"></a>5.2 Pod Security Standards</h3>
<div class="sect3">
<h4 id="_5_2_1_ensure_that_the_cluster_has_at_least_one_active_policy_control_mechanism_in_place_manual"><a class="anchor" href="#_5_2_1_ensure_that_the_cluster_has_at_least_one_active_policy_control_mechanism_in_place_manual"></a>5.2.1 Ensure that the cluster has at least one active policy control mechanism in place (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Ensure that either Pod Security Admission or an external policy control system is in place
for every namespace which contains user workloads.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_2_minimize_the_admission_of_privileged_containers_manual"><a class="anchor" href="#_5_2_2_minimize_the_admission_of_privileged_containers_manual"></a>5.2.2 Minimize the admission of privileged containers (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">whitelist="kube-flannel calico-node kube-proxy"
kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve container(s) for each Pod.
  kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o json | jq -c '.spec.containers[]' | while read -r container
  do
    # Retrieve container's name.
    container_name=$(echo ${container} | jq -r '.name')
    # Retrieve container's .securityContext.privileged value.
    container_privileged=$(echo ${container} | jq -r '.securityContext.privileged' | sed -e 's/null/notset/g')
    # Check if container name is in whitelist.
    if echo "${whitelist}" | grep -q "${container_name}"; then
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} is_container_privileged: ${container_privileged} is_whitelist: true is_compliant: true"
    elif [ "${container_privileged}" = "false" ] || [ "${container_privileged}" = "notset" ] ; then
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} is_container_privileged: ${container_privileged} is_compliant: true"
    else
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} is_container_privileged: ${container_privileged} is_compliant: false"
    fi
  done
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 container_name: cloud-controller-manager pod_namespace: kube-system is_container_privileged: false is_compliant: true
***pod_name: etcd-server-0 container_name: etcd pod_namespace: kube-system is_container_privileged: false is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n container_name: helm pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: kube-apiserver-server-0 container_name: kube-apiserver pod_namespace: kube-system is_container_privileged: false is_compliant: true
***pod_name: kube-controller-manager-server-0 container_name: kube-controller-manager pod_namespace: kube-system is_container_privileged: false is_compliant: true
***pod_name: kube-proxy-server-0 container_name: kube-proxy pod_namespace: kube-system is_container_privileged: true is_whitelist: true is_compliant: true
***pod_name: kube-scheduler-server-0 container_name: kube-scheduler pod_namespace: kube-system is_container_privileged: false is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: calico-node pod_namespace: kube-system is_container_privileged: true is_whitelist: true is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: kube-flannel pod_namespace: kube-system is_container_privileged: true is_whitelist: true is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk container_name: coredns pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf container_name: autoscaler pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m container_name: rke2-ingress-nginx-controller pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh container_name: metrics-server pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw container_name: rke2-snapshot-controller pod_namespace: kube-system is_container_privileged: notset is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 container_name: rke2-snapshot-validation-webhook pod_namespace: kube-system is_container_privileged: notset is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Add policies to each namespace in the cluster which has user workloads to restrict the
admission of privileged containers.
RKE2 gives exceptions to the following pods, which are required for regular operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>kube-flannel, calico-node, kube-proxy
Audit: the audit list all pods' containers to retrieve their .securityContext.privileged value.
Condition: is_compliant is false if container&#8217;s <code>.securityContext.privileged</code> is set to <code>true</code>.
Default: by default, there are no restrictions on the creation of privileged containers.</p>
</li>
</ul>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_3_minimize_the_admission_of_containers_wishing_to_share_the_host_process_id_namespace_manual"><a class="anchor" href="#_5_2_3_minimize_the_admission_of_containers_wishing_to_share_the_host_process_id_namespace_manual"></a>5.2.3 Minimize the admission of containers wishing to share the host process ID namespace (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve spec.hostPID for each pod.
  pod_hostpid=$(kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o jsonpath='{.spec.hostPID}' 2&gt;/dev/null)
  if [ -z "${pod_hostpid}" ]; then
    pod_hostpid="false"
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostpid: ${pod_hostpid} is_compliant: true"
  else
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostpid: ${pod_hostpid} is_compliant: false"
  fi
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: etcd-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: kube-apiserver-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: kube-controller-manager-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: kube-proxy-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: kube-scheduler-server-0 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-canal-b8l4s pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw pod_namespace: kube-system is_pod_hostpid: false is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 pod_namespace: kube-system is_pod_hostpid: false is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Add policies to each namespace in the cluster which has user workloads to restrict the
admission of <code>hostPID</code> containers.
Audit: the audit retrieves each Pod' spec.hostPID.
Condition: is_compliant is false if Pod&#8217;s spec.hostPID is set to <code>true</code>.
Default: by default, there are no restrictions on the creation of hostPID containers.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_4_minimize_the_admission_of_containers_wishing_to_share_the_host_ipc_namespace_manual"><a class="anchor" href="#_5_2_4_minimize_the_admission_of_containers_wishing_to_share_the_host_ipc_namespace_manual"></a>5.2.4 Minimize the admission of containers wishing to share the host IPC namespace (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve spec.hostIPC for each pod.
  pod_hostipc=$(kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o jsonpath='{.spec.hostIPC}' 2&gt;/dev/null)
  if [ -z "${pod_hostipc}" ]; then
    pod_hostipc="false"
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostipc: ${pod_hostipc} is_compliant: true"
  else
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostipc: ${pod_hostipc} is_compliant: false"
  fi
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: etcd-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: kube-apiserver-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: kube-controller-manager-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: kube-proxy-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: kube-scheduler-server-0 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-canal-b8l4s pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw pod_namespace: kube-system is_pod_hostipc: false is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 pod_namespace: kube-system is_pod_hostipc: false is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Add policies to each namespace in the cluster which has user workloads to restrict the
admission of <code>hostIPC</code> containers.
Audit: the audit retrieves each Pod' spec.IPC.
Condition: is_compliant is false if Pod&#8217;s spec.hostIPC is set to <code>true</code>.
Default: by default, there are no restrictions on the creation of hostIPC containers.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_5_minimize_the_admission_of_containers_wishing_to_share_the_host_network_namespace_manual"><a class="anchor" href="#_5_2_5_minimize_the_admission_of_containers_wishing_to_share_the_host_network_namespace_manual"></a>5.2.5 Minimize the admission of containers wishing to share the host network namespace (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">whitelist="cloud-controller-manager etcd rke2-canal rke2-coredns kube-apiserver kube-scheduler kube-proxy kube-controller-manager"
is_in_whitelist() {
  for entry in $whitelist; do
    case "${pod_name}" in
      *"${entry}"*)
        return 0
        ;;
    esac
  done
  return 1
}
kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve spec.hostNetwork for each pod.
  pod_hostnetwork=$(kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o jsonpath='{.spec.hostNetwork}' 2&gt;/dev/null)
  echo "${whitelist}" | grep -q "${pod_name}"
  if [ "${pod_namespace}" = 'kube-system' ] &amp;&amp; is_in_whitelist; then
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostnetwork: ${pod_hostnetwork} is_whitelist: true is_compliant: true"
  elif [ -z "${pod_hostnetwork}" ]; then
    pod_hostnetwork="false"
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostnetwork: ${pod_hostnetwork} is_compliant: true"
  else
    echo "***pod_name: ${pod_name} pod_namespace: ${pod_namespace} is_pod_hostnetwork: ${pod_hostnetwork} is_compliant: false"
  fi
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: etcd-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: kube-apiserver-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: kube-controller-manager-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: kube-proxy-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: kube-scheduler-server-0 pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: rke2-canal-b8l4s pod_namespace: kube-system is_pod_hostnetwork: true is_whitelist: true is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk pod_namespace: kube-system is_pod_hostnetwork:  is_whitelist: true is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf pod_namespace: kube-system is_pod_hostnetwork:  is_whitelist: true is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 pod_namespace: kube-system is_pod_hostnetwork: false is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Add policies to each namespace in the cluster which has user workloads to restrict the
admission of <code>hostNetwork</code> containers.
RKE2 gives exceptions to the following pods in the kube-system namespace, which are required for regular operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>cloud-controller-manager, etcd, rke2-canal, rke2-coredns, kube-apiserver,</p>
</li>
<li>
<p>kube-scheduler, kube-proxy, kube-controller-manager
Audit: the audit retrieves each Pod' spec.hostNetwork.
Condition: is_compliant is false if Pod&#8217;s spec.hostNetwork is set to <code>true</code>.
Default: by default, there are no restrictions on the creation of hostNetwork containers.</p>
</li>
</ul>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_6_minimize_the_admission_of_containers_with_allowprivilegeescalation_manual"><a class="anchor" href="#_5_2_6_minimize_the_admission_of_containers_with_allowprivilegeescalation_manual"></a>5.2.6 Minimize the admission of containers with allowPrivilegeEscalation (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve container(s) for each Pod.
  kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o json | jq -c '.spec.containers[]' | while read -r container
  do
    # Retrieve container's name
    container_name=$(echo ${container} | jq -r '.name')
    # Retrieve container's .securityContext.allowPrivilegeEscalation
    container_allowprivesc=$(echo ${container} | jq -r '.securityContext.allowPrivilegeEscalation' | sed -e 's/null/notset/g')
    if [ "${container_allowprivesc}" = "false" ] || [ "${container_allowprivesc}" = "notset" ]; then
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} is_container_allowprivesc: ${container_allowprivesc} is_compliant: true"
    else
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} is_container_allowprivesc: ${container_allowprivesc} is_compliant: false"
    fi
  done
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 container_name: cloud-controller-manager pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: etcd-server-0 container_name: etcd pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n container_name: helm pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: kube-apiserver-server-0 container_name: kube-apiserver pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: kube-controller-manager-server-0 container_name: kube-controller-manager pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: kube-proxy-server-0 container_name: kube-proxy pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: kube-scheduler-server-0 container_name: kube-scheduler pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: calico-node pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: kube-flannel pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk container_name: coredns pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf container_name: autoscaler pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m container_name: rke2-ingress-nginx-controller pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh container_name: metrics-server pod_namespace: kube-system is_container_allowprivesc: false is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw container_name: rke2-snapshot-controller pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 container_name: rke2-snapshot-validation-webhook pod_namespace: kube-system is_container_allowprivesc: notset is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Add policies to each namespace in the cluster which has user workloads to restrict the
admission of containers with <code>.securityContext.allowPrivilegeEscalation</code> set to <code>true</code>.
Audit: the audit retrieves each Pod&#8217;s container(s) <code>.securityContext.allowPrivilegeEscalation</code>.
Condition: is_compliant is false if container&#8217;s <code>.securityContext.allowPrivilegeEscalation</code> is set to <code>true</code>.
Default: If notset, privilege escalation is allowed (default to true). However if PSP/PSA is used with a <code>restricted</code> profile,
privilege escalation is explicitly disallowed unless configured otherwise.</p>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_7_minimize_the_admission_of_root_containers_manual"><a class="anchor" href="#_5_2_7_minimize_the_admission_of_root_containers_manual"></a>5.2.7 Minimize the admission of root containers (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Create a policy for each namespace in the cluster, ensuring that either <code>MustRunAsNonRoot</code>
or <code>MustRunAs</code> with the range of UIDs not including 0, is set.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_8_minimize_the_admission_of_containers_with_the_net_raw_capability_manual"><a class="anchor" href="#_5_2_8_minimize_the_admission_of_containers_with_the_net_raw_capability_manual"></a>5.2.8 Minimize the admission of containers with the NET_RAW capability (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Add policies to each namespace in the cluster which has user workloads to restrict the
admission of containers with the <code>NET_RAW</code> capability.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_9_minimize_the_admission_of_containers_with_added_capabilities_manual"><a class="anchor" href="#_5_2_9_minimize_the_admission_of_containers_with_added_capabilities_manual"></a>5.2.9 Minimize the admission of containers with added capabilities (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> PASS</p>
</div>
<div class="paragraph">
<p><strong>Audit:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">whitelist="rke2-ingress-nginx-controller coredns"
kubectl get pods --all-namespaces -o custom-columns=POD_NAME:.metadata.name,POD_NAMESPACE:.metadata.namespace --no-headers | while read -r pod_name pod_namespace
do
  # Retrieve container(s) for each Pod.
  kubectl get pod "${pod_name}" --namespace "${pod_namespace}" -o json | jq -c '.spec.containers[]' | while read -r container
  do
    # Retrieve container's name
    container_name=$(echo ${container} | jq -r '.name')
    # Retrieve container's added capabilities
    container_caps_add=$(echo ${container} | jq -r '.securityContext.capabilities.add' | sed -e 's/null/notset/g')
    # Set is_compliant to true by default.
    is_compliant=true
    is_whitelist=false
    caps_list=""
    if [ "${container_caps_add}" != "notset" ]; then
      # Loop through all caps and append caps_list, then set is_compliant to false.
      for cap in $(echo "${container_caps_add}" | jq -r '.[]'); do
        caps_list="${caps_list}${cap},"
        is_compliant=false
      done
      # Remove trailing comma for the last list member.
      caps_list=${caps_list%,}
    fi
    # Remove newline from container_caps_add for final output.
    container_caps_add=$(echo "${container_caps_add}" | tr -d '\n')
    if [ "${pod_namespace}" = "kube-system" ] &amp;&amp; echo "${whitelist}" | grep -q "${container_name}"; then
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} container_caps_add: ${container_caps_add} is_whitelist: true is_compliant: true"
    elif [ "${is_compliant}" = true ]; then
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} container_caps_add: ${container_caps_add} is_compliant: true"
    else
      echo "***pod_name: ${pod_name} container_name: ${container_name} pod_namespace: ${pod_namespace} container_caps_add: ${caps_list} is_compliant: false"
    fi
  done
done</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Expected Result:</strong> 'is_compliant' is equal to 'true'</p>
</div>
<details>
<summary class="title"><strong>Returned Value:</strong></summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-console hljs" data-lang="console">***pod_name: cloud-controller-manager-server-0 container_name: cloud-controller-manager pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: etcd-server-0 container_name: etcd pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-canal-9n9dk container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-coredns-8tv2t container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-ingress-nginx-nlmrr container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-metrics-server-n99w4 container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-crd-f9zkr container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-controller-shqn6 container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: helm-install-rke2-snapshot-validation-webhook-sfh6n container_name: helm pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: kube-apiserver-server-0 container_name: kube-apiserver pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: kube-controller-manager-server-0 container_name: kube-controller-manager pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: kube-proxy-server-0 container_name: kube-proxy pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: kube-scheduler-server-0 container_name: kube-scheduler pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: calico-node pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-canal-b8l4s container_name: kube-flannel pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-6794d5bfbb-6srrk container_name: coredns pod_namespace: kube-system container_caps_add: [  "NET_BIND_SERVICE"] is_whitelist: true is_compliant: true
***pod_name: rke2-coredns-rke2-coredns-autoscaler-694dcd9546-sc6mf container_name: autoscaler pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-ingress-nginx-controller-wqq4m container_name: rke2-ingress-nginx-controller pod_namespace: kube-system container_caps_add: [  "NET_BIND_SERVICE"] is_whitelist: true is_compliant: true
***pod_name: rke2-metrics-server-7694cf7d77-rv9qh container_name: metrics-server pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-snapshot-controller-5c9df4d7d6-ks7tw container_name: rke2-snapshot-controller pod_namespace: kube-system container_caps_add: notset is_compliant: true
***pod_name: rke2-snapshot-validation-webhook-54f487ff94-cc254 container_name: rke2-snapshot-validation-webhook pod_namespace: kube-system container_caps_add: notset is_compliant: true</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title"><strong>Remediation:</strong></summary>
<div class="content">
<div class="paragraph">
<p>Ensure that <code>allowedCapabilities</code> is not present in policies for the cluster unless
it is set to an empty array.
RKE2 gives exceptions to the following pods in the kube-system namespace, which are required for regular operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>rke2-ingress-ngninx-controller, coredns
Audit: the audit retrieves each Pod&#8217;s container(s) added capabilities.
Condition: is_compliant is false if added capabilities are added for a given container.
Default: Containers run with a default set of capabilities as assigned by the Container Runtime.</p>
</li>
</ul>
</div>
</div>
</details>
</div>
<div class="sect3">
<h4 id="_5_2_10_minimize_the_admission_of_containers_with_capabilities_assigned_manual"><a class="anchor" href="#_5_2_10_minimize_the_admission_of_containers_with_capabilities_assigned_manual"></a>5.2.10 Minimize the admission of containers with capabilities assigned (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Review the use of capabilities in applications running on your cluster. Where a namespace
contains applications which do not require any Linux capabities to operate consider adding
a PSP which forbids the admission of containers which do not drop all capabilities.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_11_minimize_the_admission_of_windows_hostprocess_containers_manual"><a class="anchor" href="#_5_2_11_minimize_the_admission_of_windows_hostprocess_containers_manual"></a>5.2.11 Minimize the admission of Windows HostProcess containers (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Add policies to each namespace in the cluster which has user workloads to restrict the
admission of containers that have <code>.securityContext.windowsOptions.hostProcess</code> set to <code>true</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_12_minimize_the_admission_of_hostpath_volumes_manual"><a class="anchor" href="#_5_2_12_minimize_the_admission_of_hostpath_volumes_manual"></a>5.2.12 Minimize the admission of HostPath volumes (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Add policies to each namespace in the cluster which has user workloads to restrict the
admission of containers with <code>hostPath</code> volumes.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_2_13_minimize_the_admission_of_containers_which_use_hostports_manual"><a class="anchor" href="#_5_2_13_minimize_the_admission_of_containers_which_use_hostports_manual"></a>5.2.13 Minimize the admission of containers which use HostPorts (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Add policies to each namespace in the cluster which has user workloads to restrict the
admission of containers which use <code>hostPort</code> sections.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_3_network_policies_and_cni"><a class="anchor" href="#_5_3_network_policies_and_cni"></a>5.3 Network Policies and CNI</h3>
<div class="sect3">
<h4 id="_5_3_1_ensure_that_the_cni_in_use_supports_networkpolicies_manual"><a class="anchor" href="#_5_3_1_ensure_that_the_cni_in_use_supports_networkpolicies_manual"></a>5.3.1 Ensure that the CNI in use supports NetworkPolicies (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
If the CNI plugin in use does not support network policies, consideration should be given to
making use of a different plugin, or finding an alternate mechanism for restricting traffic
in the Kubernetes cluster.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_3_2_ensure_that_all_namespaces_have_networkpolicies_defined_manual"><a class="anchor" href="#_5_3_2_ensure_that_all_namespaces_have_networkpolicies_defined_manual"></a>5.3.2 Ensure that all Namespaces have NetworkPolicies defined (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Follow the documentation and create NetworkPolicy objects as you need them.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_4_secrets_management"><a class="anchor" href="#_5_4_secrets_management"></a>5.4 Secrets Management</h3>
<div class="sect3">
<h4 id="_5_4_1_prefer_using_secrets_as_files_over_secrets_as_environment_variables_manual"><a class="anchor" href="#_5_4_1_prefer_using_secrets_as_files_over_secrets_as_environment_variables_manual"></a>5.4.1 Prefer using Secrets as files over Secrets as environment variables (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
If possible, rewrite application code to read Secrets from mounted secret files, rather than
from environment variables.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_4_2_consider_external_secret_storage_manual"><a class="anchor" href="#_5_4_2_consider_external_secret_storage_manual"></a>5.4.2 Consider external secret storage (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Refer to the Secrets management options offered by your cloud provider or a third-party
secrets management solution.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_5_extensible_admission_control"><a class="anchor" href="#_5_5_extensible_admission_control"></a>5.5 Extensible Admission Control</h3>
<div class="sect3">
<h4 id="_5_5_1_configure_image_provenance_using_imagepolicywebhook_admission_controller_manual"><a class="anchor" href="#_5_5_1_configure_image_provenance_using_imagepolicywebhook_admission_controller_manual"></a>5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Follow the Kubernetes documentation and setup image provenance.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_7_general_policies"><a class="anchor" href="#_5_7_general_policies"></a>5.7 General Policies</h3>
<div class="sect3">
<h4 id="_5_7_1_create_administrative_boundaries_between_resources_using_namespaces_manual"><a class="anchor" href="#_5_7_1_create_administrative_boundaries_between_resources_using_namespaces_manual"></a>5.7.1 Create administrative boundaries between resources using namespaces (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Follow the documentation and create namespaces for objects in your deployment as you need
them.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_7_2_ensure_that_the_seccomp_profile_is_set_to_dockerdefault_in_your_pod_definitions_manual"><a class="anchor" href="#_5_7_2_ensure_that_the_seccomp_profile_is_set_to_dockerdefault_in_your_pod_definitions_manual"></a>5.7.2 Ensure that the seccomp profile is set to docker/default in your Pod definitions (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Use <code>securityContext</code> to enable the docker/default seccomp profile in your pod definitions.
An example is as below:
  securityContext:
    seccompProfile:
      type: RuntimeDefault</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_7_3_apply_securitycontext_to_your_pods_and_containers_manual"><a class="anchor" href="#_5_7_3_apply_securitycontext_to_your_pods_and_containers_manual"></a>5.7.3 Apply SecurityContext to your Pods and Containers (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Follow the Kubernetes documentation and apply SecurityContexts to your Pods. For a
suggested list of SecurityContexts, you may refer to the CIS Security Benchmark for Docker
Containers.</p>
</div>
</div>
<div class="sect3">
<h4 id="_5_7_4_the_default_namespace_should_not_be_used_manual"><a class="anchor" href="#_5_7_4_the_default_namespace_should_not_be_used_manual"></a>5.7.4 The default namespace should not be used (Manual)</h4>
<div class="paragraph">
<p><strong>Result:</strong> WARN</p>
</div>
<div class="paragraph">
<p><strong>Remediation:</strong>
Ensure that namespaces are created to allow for appropriate segregation of Kubernetes
resources and that all new resources are created in a specific namespace.</p>
</div>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="cis_self_assessment111.html">CIS 1.11 Self-Assessment Guide</a></span>
  <span class="next"><a href="cis_self_assessment19.html">CIS 1.9 Self-Assessment Guide</a></span>
</nav>
</article>
  </div>
</main>
</div>
<script src="../../../../_/js/site.js"></script>
<script async src="../../../../_/js/vendor/highlight.js"></script>
<script src="../../../../_/js/vendor/lunr.js"></script>
<script src="../../../../_/js/vendor/lunr-languages.js"></script>
<script src="../../../../_/js/search-ui.js" id="search-ui-script" data-site-root-path="../../../.." data-snippet-length="100" data-stylesheet="../../../../_/css/search.css"></script>
<script async src="../../../../search-index.js"></script>
<script src="../../../../_/js/vendor/langSelection.js"></script>
<script async src="../../../../_/js/vendor/tabs.js"></script>


<script src="../../../../_/js/CNLanguageSwitcher.js"></script>
  </body>
</html>
